{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.10.15", "generated_at": "2025-12-26T23:48:19.457727Z", "invocation_id": "6b9c4f08-d05a-4544-b4fc-36ddb19e486b", "invocation_started_at": "2025-12-26T23:48:11.263942Z", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:13.978184Z", "completed_at": "2025-12-26T23:48:14.008393Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.018496Z", "completed_at": "2025-12-26T23:48:14.433270Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.4665646553039551, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_arbitrum__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from Arbitrum\r\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\r\n\r\nWITH raw_deposits AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'arbitrum')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\r\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\r\n        topic_depositor,                  -- Address of the user who initiated the deposit\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the deposit\r\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\r\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\r\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\r\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\r\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\r\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\r\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\r\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\r\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\r\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\r\n        \r\n    FROM raw.arbitrum_logs_processed\r\n    \r\n    -- Filter: Only include rows where FundsDeposited data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\r\n        AND funds_deposited_data_input_amount IS NOT NULL\r\n        AND funds_deposited_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_deposits AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        -- The ETL process may store timestamps as Unix integers or ISO strings\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS deposit_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Destination chain ID: Which blockchain the funds are being sent TO\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 8453 = Base, 137 = Polygon\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Depositor address: Who initiated the bridge transaction\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_depositor AS depositor_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address being deposited on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xaf88d065aC88dCc5619a6eeFdD463aAbdE3eE2c3 = USDC on Arbitrum\r\n        funds_deposited_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address to receive on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        funds_deposited_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was deposited on the origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        funds_deposited_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: Expected amount to receive on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread, but can vary with exchange rates\r\n        funds_deposited_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- TIMING INFORMATION (deadlines and quotes)\r\n        -- ============================================================\r\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\r\n        \r\n        -- Quote timestamp: When the exchange rate quote was generated\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Used to determine which exchange rate was used for the bridge\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\r\n        \r\n        -- Fill deadline: Latest timestamp by which the deposit must be filled\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- If not filled by this time, the deposit can be refunded\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\r\n        \r\n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\r\n        \r\n        -- ============================================================\r\n        -- USER & RELAYER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        funds_deposited_data_recipient AS recipient_address\r\n        \r\n        -- Exclusive relayer: Address with exclusive fill rights (if any)\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\r\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\r\n        \r\n    FROM raw_deposits\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    deposit_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    destination_chain_id,\r\n    deposit_id,\r\n    depositor_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Timing (commented out - available in schema but not included in output)\r\n    -- quote_timestamp,\r\n    -- fill_deadline,\r\n    -- exclusivity_deadline,\r\n    \r\n    -- User info\r\n    recipient_address\r\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\r\n    \r\nFROM cleaned_deposits\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND depositor_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_arbitrum__deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:13.999899Z", "completed_at": "2025-12-26T23:48:14.070933Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.101118Z", "completed_at": "2025-12-26T23:48:14.443603Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.4752981662750244, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_arbitrum__fills", "compiled": true, "compiled_code": "-- Staging model for FilledRelay events from Arbitrum\r\n\r\nWITH raw_fills AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'arbitrum')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_origin_chain_id,           -- Chain ID where the original deposit happened\r\n        topic_deposit_id,                -- Unique deposit identifier (links to deposit event)\r\n        topic_relayer,                   -- Address of the relayer who provided liquidity\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the fill\r\n        filled_relay_data_input_token,          -- Token address on origin chain\r\n        filled_relay_data_output_token,          -- Token address on destination chain\r\n        filled_relay_data_input_amount,          -- Amount sent (in origin token units)\r\n        filled_relay_data_output_amount,         -- Amount received (in destination token units)\r\n        filled_relay_data_repayment_chain_id,     -- Where relayer gets reimbursed\r\n        filled_relay_data_exclusive_relayer,     -- Address with exclusive fill rights (if any)\r\n        filled_relay_data_depositor,             -- Original user who initiated the bridge\r\n        filled_relay_data_recipient              -- Final recipient of the bridged funds\r\n        \r\n    FROM raw.arbitrum_logs_processed\r\n    \r\n    -- Filter: Only include rows where FilledRelay data exists\r\n    WHERE topic_0 = '0x44b559f101f8fbcc8a0ea43fa91a05a729a5ea6e14a7c75aa750374690137208'\r\n        AND filled_relay_data_input_amount IS NOT NULL\r\n        AND filled_relay_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_fills AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        \r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP can parse various formats, but we use the simplest approach\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string\r\n        END AS fill_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Origin chain ID: Which blockchain the funds came FROM\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_origin_chain_id::NUMERIC)::BIGINT AS origin_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this fill to its original deposit\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Relayer address: Who provided the liquidity\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_relayer AS relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        filled_relay_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address on the destination chain (Arbitrum in this case)\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was sent from origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        filled_relay_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: How much was received on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread\r\n        filled_relay_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- RELAYER & ROUTING INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Repayment chain ID: Where the relayer gets reimbursed\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Relayers front capital, then get paid back (often on a different chain)\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1.0\" from ETL\r\n        (filled_relay_data_repayment_chain_id::NUMERIC)::BIGINT AS repayment_chain_id,\r\n        \r\n        -- Exclusive relayer: If set, only this address can fill this deposit\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        filled_relay_data_exclusive_relayer AS exclusive_relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- USER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Depositor: The original user who initiated the bridge\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_depositor AS depositor_address,\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        filled_relay_data_recipient AS recipient_address\r\n        \r\n    FROM raw_fills\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    fill_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    origin_chain_id,\r\n    deposit_id,\r\n    relayer_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Relayer routing\r\n    repayment_chain_id,\r\n    exclusive_relayer_address,\r\n    \r\n    -- User info\r\n    depositor_address,\r\n    recipient_address\r\n    \r\nFROM cleaned_fills\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND relayer_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_arbitrum__fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:14.012900Z", "completed_at": "2025-12-26T23:48:14.107316Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.110110Z", "completed_at": "2025-12-26T23:48:14.445497Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.45086121559143066, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_ethereum__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from Ethereum\r\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\r\n\r\nWITH raw_deposits AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'ethereum')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\r\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\r\n        topic_depositor,                  -- Address of the user who initiated the deposit\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the deposit\r\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\r\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\r\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\r\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\r\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\r\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\r\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\r\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\r\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\r\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\r\n        \r\n    FROM raw.ethereum_logs_processed\r\n    \r\n    -- Filter: Only include rows where FundsDeposited data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\r\n        AND funds_deposited_data_input_amount IS NOT NULL\r\n        AND funds_deposited_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_deposits AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        -- The ETL process may store timestamps as Unix integers or ISO strings\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS deposit_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Destination chain ID: Which blockchain the funds are being sent TO\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 8453 = Base, 137 = Polygon\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Depositor address: Who initiated the bridge transaction\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_depositor AS depositor_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address being deposited on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        funds_deposited_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address to receive on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xaf88d065aC88dCc5619a6eeFdD463aAbdE3eE2c3 = USDC on Arbitrum\r\n        funds_deposited_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was deposited on the origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        funds_deposited_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: Expected amount to receive on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread, but can vary with exchange rates\r\n        funds_deposited_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- TIMING INFORMATION (deadlines and quotes)\r\n        -- ============================================================\r\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\r\n        \r\n        -- Quote timestamp: When the exchange rate quote was generated\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Used to determine which exchange rate was used for the bridge\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\r\n        \r\n        -- Fill deadline: Latest timestamp by which the deposit must be filled\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- If not filled by this time, the deposit can be refunded\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\r\n        \r\n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\r\n        \r\n        -- ============================================================\r\n        -- USER & RELAYER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        funds_deposited_data_recipient AS recipient_address\r\n        \r\n        -- Exclusive relayer: Address with exclusive fill rights (if any)\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\r\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\r\n        \r\n    FROM raw_deposits\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    deposit_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    destination_chain_id,\r\n    deposit_id,\r\n    depositor_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Timing (commented out - available in schema but not included in output)\r\n    -- quote_timestamp,\r\n    -- fill_deadline,\r\n    -- exclusivity_deadline,\r\n    \r\n    -- User info\r\n    recipient_address\r\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\r\n    \r\nFROM cleaned_deposits\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND depositor_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_ethereum__deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:14.049727Z", "completed_at": "2025-12-26T23:48:14.108606Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.114932Z", "completed_at": "2025-12-26T23:48:14.437660Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.4438323974609375, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_arbitrum__refunds", "compiled": true, "compiled_code": "-- Staging model for ExecutedRelayerRefundRoot events from Arbitrum\r\n\r\nWITH raw_refunds AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'arbitrum')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_chain_id,                  -- Chain ID where the refund was executed\r\n        topic_root_bundle_id,            -- Merkle root bundle identifier (groups multiple refunds)\r\n        topic_leaf_id,                   -- Leaf index in the merkle tree (identifies this specific refund batch)\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the refund\r\n        amount_to_return,                -- Total amount of capital returned in this batch\r\n        l2_token_address,                -- Token address being refunded (on Arbitrum L2)\r\n        refund_amounts,                  -- Comma-separated list of individual refund amounts\r\n        refund_addresses,                -- Comma-separated list of relayer addresses receiving refunds\r\n        refund_count                     -- Number of relayers being refunded in this batch\r\n        \r\n    FROM raw.arbitrum_logs_processed\r\n    \r\n    -- Filter: Only include rows where ExecutedRelayerRefundRoot data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0xf4ad92585b1bc117fbdd644990adf0827bc4c95baeae8a23322af807b6d0020e'\r\n        AND amount_to_return IS NOT NULL\r\n        AND l2_token_address IS NOT NULL\r\n        AND refund_count IS NOT NULL\r\n),\r\n\r\ncleaned_refunds AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS refund_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Chain ID: Which blockchain this refund was executed on\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 1 = Ethereum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"42161.0\" from ETL\r\n        (topic_chain_id::NUMERIC)::BIGINT AS chain_id,\r\n        \r\n        -- Root bundle ID: Groups multiple refunds together in a merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Multiple refund batches can be grouped into one merkle root for gas efficiency\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_root_bundle_id::NUMERIC)::BIGINT AS root_bundle_id,\r\n        \r\n        -- Leaf ID: Identifies this specific refund batch within the merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Each leaf represents one batch of refunds to multiple relayers\r\n        -- Cast via NUMERIC first to handle decimal strings like \"789.0\" from ETL\r\n        (topic_leaf_id::NUMERIC)::BIGINT AS leaf_id,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was refunded)\r\n        -- ============================================================\r\n        \r\n        -- L2 token address: The token being refunded on Arbitrum\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        -- Example: 0xaf88d065aC88dCc5619a6eeFdD463aAbdE3eE2c3 = USDC on Arbitrum\r\n        l2_token_address AS refund_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was refunded)\r\n        -- ============================================================\r\n        \r\n        -- Amount to return: Total capital returned in this batch\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- This is the sum of all individual refund amounts in the batch\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        amount_to_return::NUMERIC AS total_refund_amount,\r\n        \r\n        -- Refund amounts: Individual refund amounts as comma-separated string\r\n        -- Format: \"1000000000000000000,2000000000000000000,3000000000000000000\"\r\n        -- Each value is in token's base units (e.g., wei for ETH, 6 decimals for USDC)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_amounts AS refund_amounts_string,\r\n        \r\n        -- Refund addresses: Relayer addresses receiving refunds as comma-separated string\r\n        -- Format: \"0xAAA...,0xBBB...,0xCCC...\"\r\n        -- Matches 1:1 with refund_amounts (first address gets first amount, etc.)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_addresses AS refund_addresses_string,\r\n        \r\n        -- Refund count: Number of relayers being refunded in this batch\r\n        -- Already converted by ETL to integer\r\n        -- This tells us how many individual refunds are in the arrays above\r\n        refund_count::INTEGER AS refund_count\r\n        \r\n    FROM raw_refunds\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    refund_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields (merkle tree identifiers)\r\n    chain_id,\r\n    root_bundle_id,\r\n    leaf_id,\r\n    \r\n    -- Token info\r\n    refund_token_address,\r\n    \r\n    -- Amounts\r\n    total_refund_amount,\r\n    refund_amounts_string,\r\n    refund_addresses_string,\r\n    refund_count\r\n    \r\nFROM cleaned_refunds\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE chain_id IS NOT NULL\r\n    AND refund_token_address IS NOT NULL\r\n    AND total_refund_amount IS NOT NULL\r\n    AND refund_count IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_arbitrum__refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:14.490260Z", "completed_at": "2025-12-26T23:48:14.507075Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.512846Z", "completed_at": "2025-12-26T23:48:14.888136Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.4102649688720703, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_ethereum__refunds", "compiled": true, "compiled_code": "-- Staging model for ExecutedRelayerRefundRoot events from Ethereum\r\n\r\nWITH raw_refunds AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'ethereum')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_chain_id,                  -- Chain ID where the refund was executed\r\n        topic_root_bundle_id,            -- Merkle root bundle identifier (groups multiple refunds)\r\n        topic_leaf_id,                   -- Leaf index in the merkle tree (identifies this specific refund batch)\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the refund\r\n        amount_to_return,                -- Total amount of capital returned in this batch\r\n        l2_token_address,                -- Token address being refunded (on Ethereum L1)\r\n        refund_amounts,                  -- Comma-separated list of individual refund amounts\r\n        refund_addresses,                -- Comma-separated list of relayer addresses receiving refunds\r\n        refund_count                     -- Number of relayers being refunded in this batch\r\n        \r\n    FROM raw.ethereum_logs_processed\r\n    \r\n    -- Filter: Only include rows where ExecutedRelayerRefundRoot data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0xf4ad92585b1bc117fbdd644990adf0827bc4c95baeae8a23322af807b6d0020e'\r\n        AND amount_to_return IS NOT NULL\r\n        AND l2_token_address IS NOT NULL\r\n        AND refund_count IS NOT NULL\r\n),\r\n\r\ncleaned_refunds AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS refund_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Chain ID: Which blockchain this refund was executed on\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 1 = Ethereum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"42161.0\" from ETL\r\n        (topic_chain_id::NUMERIC)::BIGINT AS chain_id,\r\n        \r\n        -- Root bundle ID: Groups multiple refunds together in a merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Multiple refund batches can be grouped into one merkle root for gas efficiency\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_root_bundle_id::NUMERIC)::BIGINT AS root_bundle_id,\r\n        \r\n        -- Leaf ID: Identifies this specific refund batch within the merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Each leaf represents one batch of refunds to multiple relayers\r\n        -- Cast via NUMERIC first to handle decimal strings like \"789.0\" from ETL\r\n        (topic_leaf_id::NUMERIC)::BIGINT AS leaf_id,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was refunded)\r\n        -- ============================================================\r\n        \r\n        -- L2 token address: The token being refunded on Ethereum\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        l2_token_address AS refund_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was refunded)\r\n        -- ============================================================\r\n        \r\n        -- Amount to return: Total capital returned in this batch\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- This is the sum of all individual refund amounts in the batch\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        amount_to_return::NUMERIC AS total_refund_amount,\r\n        \r\n        -- Refund amounts: Individual refund amounts as comma-separated string\r\n        -- Format: \"1000000000000000000,2000000000000000000,3000000000000000000\"\r\n        -- Each value is in token's base units (e.g., wei for ETH, 6 decimals for USDC)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_amounts AS refund_amounts_string,\r\n        \r\n        -- Refund addresses: Relayer addresses receiving refunds as comma-separated string\r\n        -- Format: \"0xAAA...,0xBBB...,0xCCC...\"\r\n        -- Matches 1:1 with refund_amounts (first address gets first amount, etc.)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_addresses AS refund_addresses_string,\r\n        \r\n        -- Refund count: Number of relayers being refunded in this batch\r\n        -- Already converted by ETL to integer\r\n        -- This tells us how many individual refunds are in the arrays above\r\n        refund_count::INTEGER AS refund_count\r\n        \r\n    FROM raw_refunds\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    refund_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields (merkle tree identifiers)\r\n    chain_id,\r\n    root_bundle_id,\r\n    leaf_id,\r\n    \r\n    -- Token info\r\n    refund_token_address,\r\n    \r\n    -- Amounts\r\n    total_refund_amount,\r\n    refund_amounts_string,\r\n    refund_addresses_string,\r\n    refund_count\r\n    \r\nFROM cleaned_refunds\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE chain_id IS NOT NULL\r\n    AND refund_token_address IS NOT NULL\r\n    AND total_refund_amount IS NOT NULL\r\n    AND refund_count IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_ethereum__refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:14.500376Z", "completed_at": "2025-12-26T23:48:14.510473Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.523932Z", "completed_at": "2025-12-26T23:48:14.893546Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.4046204090118408, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_hyperevm__fills", "compiled": true, "compiled_code": "-- Staging model for FilledRelay events from HyperEVM\r\n\r\nWITH raw_fills AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'hyperevm')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_origin_chain_id,           -- Chain ID where the original deposit happened\r\n        topic_deposit_id,                -- Unique deposit identifier (links to deposit event)\r\n        topic_relayer,                   -- Address of the relayer who provided liquidity\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the fill\r\n        filled_relay_data_input_token,          -- Token address on origin chain\r\n        filled_relay_data_output_token,          -- Token address on destination chain\r\n        filled_relay_data_input_amount,          -- Amount sent (in origin token units)\r\n        filled_relay_data_output_amount,         -- Amount received (in destination token units)\r\n        filled_relay_data_repayment_chain_id,     -- Where relayer gets reimbursed\r\n        filled_relay_data_exclusive_relayer,     -- Address with exclusive fill rights (if any)\r\n        filled_relay_data_depositor,             -- Original user who initiated the bridge\r\n        filled_relay_data_recipient              -- Final recipient of the bridged funds\r\n        \r\n    FROM raw.hyperevm_logs_processed\r\n    \r\n    -- Filter: Only include rows where FilledRelay data exists\r\n    WHERE topic_0 = '0x44b559f101f8fbcc8a0ea43fa91a05a729a5ea6e14a7c75aa750374690137208'\r\n        AND filled_relay_data_input_amount IS NOT NULL\r\n        AND filled_relay_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_fills AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        \r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP can parse various formats, but we use the simplest approach\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string\r\n        END AS fill_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Origin chain ID: Which blockchain the funds came FROM\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_origin_chain_id::NUMERIC)::BIGINT AS origin_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this fill to its original deposit\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Relayer address: Who provided the liquidity\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_relayer AS relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        filled_relay_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address on the destination chain (HyperEVM in this case)\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was sent from origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        filled_relay_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: How much was received on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread\r\n        filled_relay_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- RELAYER & ROUTING INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Repayment chain ID: Where the relayer gets reimbursed\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Relayers front capital, then get paid back (often on a different chain)\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1.0\" from ETL\r\n        (filled_relay_data_repayment_chain_id::NUMERIC)::BIGINT AS repayment_chain_id,\r\n        \r\n        -- Exclusive relayer: If set, only this address can fill this deposit\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        filled_relay_data_exclusive_relayer AS exclusive_relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- USER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Depositor: The original user who initiated the bridge\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_depositor AS depositor_address,\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        filled_relay_data_recipient AS recipient_address\r\n        \r\n    FROM raw_fills\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    fill_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    origin_chain_id,\r\n    deposit_id,\r\n    relayer_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Relayer routing\r\n    repayment_chain_id,\r\n    exclusive_relayer_address,\r\n    \r\n    -- User info\r\n    depositor_address,\r\n    recipient_address\r\n    \r\nFROM cleaned_fills\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND relayer_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_hyperevm__fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:14.482925Z", "completed_at": "2025-12-26T23:48:14.511693Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.534541Z", "completed_at": "2025-12-26T23:48:14.948178Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.47660088539123535, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_ethereum__fills", "compiled": true, "compiled_code": "-- Staging model for FilledRelay events from Ethereum\r\n\r\nWITH raw_fills AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'ethereum')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_origin_chain_id,           -- Chain ID where the original deposit happened\r\n        topic_deposit_id,                -- Unique deposit identifier (links to deposit event)\r\n        topic_relayer,                   -- Address of the relayer who provided liquidity\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the fill\r\n        filled_relay_data_input_token,          -- Token address on origin chain\r\n        filled_relay_data_output_token,          -- Token address on destination chain\r\n        filled_relay_data_input_amount,          -- Amount sent (in origin token units)\r\n        filled_relay_data_output_amount,         -- Amount received (in destination token units)\r\n        filled_relay_data_repayment_chain_id,     -- Where relayer gets reimbursed\r\n        filled_relay_data_exclusive_relayer,     -- Address with exclusive fill rights (if any)\r\n        filled_relay_data_depositor,             -- Original user who initiated the bridge\r\n        filled_relay_data_recipient              -- Final recipient of the bridged funds\r\n        \r\n    FROM raw.ethereum_logs_processed\r\n    \r\n    -- Filter: Only include rows where FilledRelay data exists\r\n    WHERE topic_0 = '0x44b559f101f8fbcc8a0ea43fa91a05a729a5ea6e14a7c75aa750374690137208'\r\n        AND filled_relay_data_input_amount IS NOT NULL\r\n        AND filled_relay_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_fills AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        \r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP can parse various formats, but we use the simplest approach\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string\r\n        END AS fill_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Origin chain ID: Which blockchain the funds came FROM\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_origin_chain_id::NUMERIC)::BIGINT AS origin_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this fill to its original deposit\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Relayer address: Who provided the liquidity\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_relayer AS relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        filled_relay_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address on the destination chain (Ethereum in this case)\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was sent from origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        filled_relay_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: How much was received on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread\r\n        filled_relay_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- RELAYER & ROUTING INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Repayment chain ID: Where the relayer gets reimbursed\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Relayers front capital, then get paid back (often on a different chain)\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1.0\" from ETL\r\n        (filled_relay_data_repayment_chain_id::NUMERIC)::BIGINT AS repayment_chain_id,\r\n        \r\n        -- Exclusive relayer: If set, only this address can fill this deposit\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        filled_relay_data_exclusive_relayer AS exclusive_relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- USER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Depositor: The original user who initiated the bridge\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_depositor AS depositor_address,\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        filled_relay_data_recipient AS recipient_address\r\n        \r\n    FROM raw_fills\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    fill_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    origin_chain_id,\r\n    deposit_id,\r\n    relayer_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Relayer routing\r\n    repayment_chain_id,\r\n    exclusive_relayer_address,\r\n    \r\n    -- User info\r\n    depositor_address,\r\n    recipient_address\r\n    \r\nFROM cleaned_fills\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND relayer_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_ethereum__fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:14.548160Z", "completed_at": "2025-12-26T23:48:14.565025Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.569874Z", "completed_at": "2025-12-26T23:48:14.953680Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.422466516494751, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_hyperevm__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from HyperEVM\r\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\r\n\r\nWITH raw_deposits AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'hyperevm')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\r\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\r\n        topic_depositor,                  -- Address of the user who initiated the deposit\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the deposit\r\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\r\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\r\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\r\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\r\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\r\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\r\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\r\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\r\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\r\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\r\n        \r\n    FROM raw.hyperevm_logs_processed\r\n    \r\n    -- Filter: Only include rows where FundsDeposited data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\r\n        AND funds_deposited_data_input_amount IS NOT NULL\r\n        AND funds_deposited_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_deposits AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        -- The ETL process may store timestamps as Unix integers or ISO strings\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS deposit_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Destination chain ID: Which blockchain the funds are being sent TO\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Depositor address: Who initiated the bridge transaction\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_depositor AS depositor_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address being deposited on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on HyperEVM\r\n        funds_deposited_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address to receive on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on destination chain\r\n        funds_deposited_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was deposited on the origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        funds_deposited_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: Expected amount to receive on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread, but can vary with exchange rates\r\n        funds_deposited_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- TIMING INFORMATION (deadlines and quotes)\r\n        -- ============================================================\r\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\r\n        \r\n        -- Quote timestamp: When the exchange rate quote was generated\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Used to determine which exchange rate was used for the bridge\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\r\n        \r\n        -- Fill deadline: Latest timestamp by which the deposit must be filled\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- If not filled by this time, the deposit can be refunded\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\r\n        \r\n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\r\n        \r\n        -- ============================================================\r\n        -- USER & RELAYER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        funds_deposited_data_recipient AS recipient_address\r\n        \r\n        -- Exclusive relayer: Address with exclusive fill rights (if any)\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\r\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\r\n        \r\n    FROM raw_deposits\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    deposit_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    destination_chain_id,\r\n    deposit_id,\r\n    depositor_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Timing (commented out - available in schema but not included in output)\r\n    -- quote_timestamp,\r\n    -- fill_deadline,\r\n    -- exclusivity_deadline,\r\n    \r\n    -- User info\r\n    recipient_address\r\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\r\n    \r\nFROM cleaned_deposits\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND depositor_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_hyperevm__deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:15.013536Z", "completed_at": "2025-12-26T23:48:15.032256Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:15.033507Z", "completed_at": "2025-12-26T23:48:15.371110Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.37595653533935547, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_linea__fills", "compiled": true, "compiled_code": "-- Staging model for FilledRelay events from Linea\r\n\r\nWITH raw_fills AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'linea')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_origin_chain_id,           -- Chain ID where the original deposit happened\r\n        topic_deposit_id,                -- Unique deposit identifier (links to deposit event)\r\n        topic_relayer,                   -- Address of the relayer who provided liquidity\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the fill\r\n        filled_relay_data_input_token,          -- Token address on origin chain\r\n        filled_relay_data_output_token,          -- Token address on destination chain\r\n        filled_relay_data_input_amount,          -- Amount sent (in origin token units)\r\n        filled_relay_data_output_amount,         -- Amount received (in destination token units)\r\n        filled_relay_data_repayment_chain_id,     -- Where relayer gets reimbursed\r\n        filled_relay_data_exclusive_relayer,     -- Address with exclusive fill rights (if any)\r\n        filled_relay_data_depositor,             -- Original user who initiated the bridge\r\n        filled_relay_data_recipient              -- Final recipient of the bridged funds\r\n        \r\n    FROM raw.linea_logs_processed\r\n    \r\n    -- Filter: Only include rows where FilledRelay data exists\r\n    WHERE topic_0 = '0x44b559f101f8fbcc8a0ea43fa91a05a729a5ea6e14a7c75aa750374690137208'\r\n        AND filled_relay_data_input_amount IS NOT NULL\r\n        AND filled_relay_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_fills AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        \r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP can parse various formats, but we use the simplest approach\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string\r\n        END AS fill_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Origin chain ID: Which blockchain the funds came FROM\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_origin_chain_id::NUMERIC)::BIGINT AS origin_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this fill to its original deposit\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Relayer address: Who provided the liquidity\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_relayer AS relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        filled_relay_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address on the destination chain (Linea in this case)\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was sent from origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        filled_relay_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: How much was received on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread\r\n        filled_relay_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- RELAYER & ROUTING INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Repayment chain ID: Where the relayer gets reimbursed\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Relayers front capital, then get paid back (often on a different chain)\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1.0\" from ETL\r\n        (filled_relay_data_repayment_chain_id::NUMERIC)::BIGINT AS repayment_chain_id,\r\n        \r\n        -- Exclusive relayer: If set, only this address can fill this deposit\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        filled_relay_data_exclusive_relayer AS exclusive_relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- USER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Depositor: The original user who initiated the bridge\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_depositor AS depositor_address,\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        filled_relay_data_recipient AS recipient_address\r\n        \r\n    FROM raw_fills\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    fill_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    origin_chain_id,\r\n    deposit_id,\r\n    relayer_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Relayer routing\r\n    repayment_chain_id,\r\n    exclusive_relayer_address,\r\n    \r\n    -- User info\r\n    depositor_address,\r\n    recipient_address\r\n    \r\nFROM cleaned_fills\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND relayer_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_linea__fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:14.959454Z", "completed_at": "2025-12-26T23:48:14.988557Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.993281Z", "completed_at": "2025-12-26T23:48:15.386884Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.4522991180419922, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_linea__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from Linea\r\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\r\n\r\nWITH raw_deposits AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'linea')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\r\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\r\n        topic_depositor,                  -- Address of the user who initiated the deposit\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the deposit\r\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\r\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\r\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\r\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\r\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\r\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\r\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\r\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\r\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\r\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\r\n        \r\n    FROM raw.linea_logs_processed\r\n    \r\n    -- Filter: Only include rows where FundsDeposited data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\r\n        AND funds_deposited_data_input_amount IS NOT NULL\r\n        AND funds_deposited_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_deposits AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        -- The ETL process may store timestamps as Unix integers or ISO strings\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS deposit_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Destination chain ID: Which blockchain the funds are being sent TO\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Depositor address: Who initiated the bridge transaction\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_depositor AS depositor_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address being deposited on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on Linea\r\n        funds_deposited_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address to receive on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on destination chain\r\n        funds_deposited_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was deposited on the origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        funds_deposited_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: Expected amount to receive on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread, but can vary with exchange rates\r\n        funds_deposited_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- TIMING INFORMATION (deadlines and quotes)\r\n        -- ============================================================\r\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\r\n        \r\n        -- Quote timestamp: When the exchange rate quote was generated\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Used to determine which exchange rate was used for the bridge\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\r\n        \r\n        -- Fill deadline: Latest timestamp by which the deposit must be filled\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- If not filled by this time, the deposit can be refunded\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\r\n        \r\n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\r\n        \r\n        -- ============================================================\r\n        -- USER & RELAYER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        funds_deposited_data_recipient AS recipient_address\r\n        \r\n        -- Exclusive relayer: Address with exclusive fill rights (if any)\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\r\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\r\n        \r\n    FROM raw_deposits\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    deposit_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    destination_chain_id,\r\n    deposit_id,\r\n    depositor_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Timing (commented out - available in schema but not included in output)\r\n    -- quote_timestamp,\r\n    -- fill_deadline,\r\n    -- exclusivity_deadline,\r\n    \r\n    -- User info\r\n    recipient_address\r\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\r\n    \r\nFROM cleaned_deposits\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND depositor_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_linea__deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:14.936593Z", "completed_at": "2025-12-26T23:48:14.957823Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:14.970155Z", "completed_at": "2025-12-26T23:48:15.446747Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.5211691856384277, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_hyperevm__refunds", "compiled": true, "compiled_code": "-- Staging model for ExecutedRelayerRefundRoot events from HyperEVM\r\n\r\nWITH raw_refunds AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'hyperevm')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_chain_id,                  -- Chain ID where the refund was executed\r\n        topic_root_bundle_id,            -- Merkle root bundle identifier (groups multiple refunds)\r\n        topic_leaf_id,                   -- Leaf index in the merkle tree (identifies this specific refund batch)\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the refund\r\n        amount_to_return,                -- Total amount of capital returned in this batch\r\n        l2_token_address,                -- Token address being refunded (on HyperEVM)\r\n        refund_amounts,                  -- Comma-separated list of individual refund amounts\r\n        refund_addresses,                -- Comma-separated list of relayer addresses receiving refunds\r\n        refund_count                     -- Number of relayers being refunded in this batch\r\n        \r\n    FROM raw.hyperevm_logs_processed\r\n    \r\n    -- Filter: Only include rows where ExecutedRelayerRefundRoot data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0xf4ad92585b1bc117fbdd644990adf0827bc4c95baeae8a23322af807b6d0020e'\r\n        AND amount_to_return IS NOT NULL\r\n        AND l2_token_address IS NOT NULL\r\n        AND refund_count IS NOT NULL\r\n),\r\n\r\ncleaned_refunds AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS refund_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Chain ID: Which blockchain this refund was executed on\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 1 = Ethereum, 999 = HyperEVM\r\n        -- Cast via NUMERIC first to handle decimal strings like \"42161.0\" from ETL\r\n        (topic_chain_id::NUMERIC)::BIGINT AS chain_id,\r\n        \r\n        -- Root bundle ID: Groups multiple refunds together in a merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Multiple refund batches can be grouped into one merkle root for gas efficiency\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_root_bundle_id::NUMERIC)::BIGINT AS root_bundle_id,\r\n        \r\n        -- Leaf ID: Identifies this specific refund batch within the merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Each leaf represents one batch of refunds to multiple relayers\r\n        -- Cast via NUMERIC first to handle decimal strings like \"789.0\" from ETL\r\n        (topic_leaf_id::NUMERIC)::BIGINT AS leaf_id,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was refunded)\r\n        -- ============================================================\r\n        \r\n        -- L2 token address: The token being refunded on HyperEVM\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        -- This is the token address on the HyperEVM chain\r\n        l2_token_address AS refund_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was refunded)\r\n        -- ============================================================\r\n        \r\n        -- Amount to return: Total capital returned in this batch\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- This is the sum of all individual refund amounts in the batch\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        amount_to_return::NUMERIC AS total_refund_amount,\r\n        \r\n        -- Refund amounts: Individual refund amounts as comma-separated string\r\n        -- Format: \"1000000000000000000,2000000000000000000,3000000000000000000\"\r\n        -- Each value is in token's base units (e.g., wei for ETH, 6 decimals for USDC)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_amounts AS refund_amounts_string,\r\n        \r\n        -- Refund addresses: Relayer addresses receiving refunds as comma-separated string\r\n        -- Format: \"0xAAA...,0xBBB...,0xCCC...\"\r\n        -- Matches 1:1 with refund_amounts (first address gets first amount, etc.)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_addresses AS refund_addresses_string,\r\n        \r\n        -- Refund count: Number of relayers being refunded in this batch\r\n        -- Already converted by ETL to integer\r\n        -- This tells us how many individual refunds are in the arrays above\r\n        refund_count::INTEGER AS refund_count\r\n        \r\n    FROM raw_refunds\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    refund_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields (merkle tree identifiers)\r\n    chain_id,\r\n    root_bundle_id,\r\n    leaf_id,\r\n    \r\n    -- Token info\r\n    refund_token_address,\r\n    \r\n    -- Amounts\r\n    total_refund_amount,\r\n    refund_amounts_string,\r\n    refund_addresses_string,\r\n    refund_count\r\n    \r\nFROM cleaned_refunds\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE chain_id IS NOT NULL\r\n    AND refund_token_address IS NOT NULL\r\n    AND total_refund_amount IS NOT NULL\r\n    AND refund_count IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_hyperevm__refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:15.019331Z", "completed_at": "2025-12-26T23:48:15.038807Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:15.041948Z", "completed_at": "2025-12-26T23:48:15.455260Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.4616849422454834, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_linea__refunds", "compiled": true, "compiled_code": "-- Staging model for ExecutedRelayerRefundRoot events from Linea\r\n\r\nWITH raw_refunds AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'linea')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_chain_id,                  -- Chain ID where the refund was executed\r\n        topic_root_bundle_id,            -- Merkle root bundle identifier (groups multiple refunds)\r\n        topic_leaf_id,                   -- Leaf index in the merkle tree (identifies this specific refund batch)\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the refund\r\n        amount_to_return,                -- Total amount of capital returned in this batch\r\n        l2_token_address,                -- Token address being refunded (on Linea)\r\n        refund_amounts,                  -- Comma-separated list of individual refund amounts\r\n        refund_addresses,                -- Comma-separated list of relayer addresses receiving refunds\r\n        refund_count                     -- Number of relayers being refunded in this batch\r\n        \r\n    FROM raw.linea_logs_processed\r\n    \r\n    -- Filter: Only include rows where ExecutedRelayerRefundRoot data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0xf4ad92585b1bc117fbdd644990adf0827bc4c95baeae8a23322af807b6d0020e'\r\n        AND amount_to_return IS NOT NULL\r\n        AND l2_token_address IS NOT NULL\r\n        AND refund_count IS NOT NULL\r\n),\r\n\r\ncleaned_refunds AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS refund_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Chain ID: Which blockchain this refund was executed on\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 1 = Ethereum, 59144 = Linea\r\n        -- Cast via NUMERIC first to handle decimal strings like \"42161.0\" from ETL\r\n        (topic_chain_id::NUMERIC)::BIGINT AS chain_id,\r\n        \r\n        -- Root bundle ID: Groups multiple refunds together in a merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Multiple refund batches can be grouped into one merkle root for gas efficiency\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_root_bundle_id::NUMERIC)::BIGINT AS root_bundle_id,\r\n        \r\n        -- Leaf ID: Identifies this specific refund batch within the merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Each leaf represents one batch of refunds to multiple relayers\r\n        -- Cast via NUMERIC first to handle decimal strings like \"789.0\" from ETL\r\n        (topic_leaf_id::NUMERIC)::BIGINT AS leaf_id,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was refunded)\r\n        -- ============================================================\r\n        \r\n        -- L2 token address: The token being refunded on Linea\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        -- Example: 0x176211869cA2b568f2A7D4EE941E07aA25fee00b = USDC on Linea\r\n        l2_token_address AS refund_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was refunded)\r\n        -- ============================================================\r\n        \r\n        -- Amount to return: Total capital returned in this batch\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- This is the sum of all individual refund amounts in the batch\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        amount_to_return::NUMERIC AS total_refund_amount,\r\n        \r\n        -- Refund amounts: Individual refund amounts as comma-separated string\r\n        -- Format: \"1000000000000000000,2000000000000000000,3000000000000000000\"\r\n        -- Each value is in token's base units (e.g., wei for ETH, 6 decimals for USDC)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_amounts AS refund_amounts_string,\r\n        \r\n        -- Refund addresses: Relayer addresses receiving refunds as comma-separated string\r\n        -- Format: \"0xAAA...,0xBBB...,0xCCC...\"\r\n        -- Matches 1:1 with refund_amounts (first address gets first amount, etc.)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_addresses AS refund_addresses_string,\r\n        \r\n        -- Refund count: Number of relayers being refunded in this batch\r\n        -- Already converted by ETL to integer\r\n        -- This tells us how many individual refunds are in the arrays above\r\n        refund_count::INTEGER AS refund_count\r\n        \r\n    FROM raw_refunds\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    refund_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields (merkle tree identifiers)\r\n    chain_id,\r\n    root_bundle_id,\r\n    leaf_id,\r\n    \r\n    -- Token info\r\n    refund_token_address,\r\n    \r\n    -- Amounts\r\n    total_refund_amount,\r\n    refund_amounts_string,\r\n    refund_addresses_string,\r\n    refund_count\r\n    \r\nFROM cleaned_refunds\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE chain_id IS NOT NULL\r\n    AND refund_token_address IS NOT NULL\r\n    AND total_refund_amount IS NOT NULL\r\n    AND refund_count IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_linea__refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:15.475387Z", "completed_at": "2025-12-26T23:48:15.505443Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:15.512772Z", "completed_at": "2025-12-26T23:48:15.860159Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.40121912956237793, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_monad__fills", "compiled": true, "compiled_code": "-- Staging model for FilledRelay events from Monad\r\n\r\nWITH raw_fills AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'monad')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_origin_chain_id,           -- Chain ID where the original deposit happened\r\n        topic_deposit_id,                -- Unique deposit identifier (links to deposit event)\r\n        topic_relayer,                   -- Address of the relayer who provided liquidity\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the fill\r\n        filled_relay_data_input_token,          -- Token address on origin chain\r\n        filled_relay_data_output_token,          -- Token address on destination chain\r\n        filled_relay_data_input_amount,          -- Amount sent (in origin token units)\r\n        filled_relay_data_output_amount,         -- Amount received (in destination token units)\r\n        filled_relay_data_repayment_chain_id,     -- Where relayer gets reimbursed\r\n        filled_relay_data_exclusive_relayer,     -- Address with exclusive fill rights (if any)\r\n        filled_relay_data_depositor,             -- Original user who initiated the bridge\r\n        filled_relay_data_recipient              -- Final recipient of the bridged funds\r\n        \r\n    FROM raw.monad_logs_processed\r\n    \r\n    -- Filter: Only include rows where FilledRelay data exists\r\n    WHERE topic_0 = '0x44b559f101f8fbcc8a0ea43fa91a05a729a5ea6e14a7c75aa750374690137208'\r\n        AND filled_relay_data_input_amount IS NOT NULL\r\n        AND filled_relay_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_fills AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        \r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP can parse various formats, but we use the simplest approach\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string\r\n        END AS fill_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Origin chain ID: Which blockchain the funds came FROM\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_origin_chain_id::NUMERIC)::BIGINT AS origin_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this fill to its original deposit\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Relayer address: Who provided the liquidity\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_relayer AS relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        filled_relay_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address on the destination chain (Monad in this case)\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was sent from origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        filled_relay_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: How much was received on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread\r\n        filled_relay_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- RELAYER & ROUTING INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Repayment chain ID: Where the relayer gets reimbursed\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Relayers front capital, then get paid back (often on a different chain)\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1.0\" from ETL\r\n        (filled_relay_data_repayment_chain_id::NUMERIC)::BIGINT AS repayment_chain_id,\r\n        \r\n        -- Exclusive relayer: If set, only this address can fill this deposit\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        filled_relay_data_exclusive_relayer AS exclusive_relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- USER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Depositor: The original user who initiated the bridge\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_depositor AS depositor_address,\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        filled_relay_data_recipient AS recipient_address\r\n        \r\n    FROM raw_fills\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    fill_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    origin_chain_id,\r\n    deposit_id,\r\n    relayer_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Relayer routing\r\n    repayment_chain_id,\r\n    exclusive_relayer_address,\r\n    \r\n    -- User info\r\n    depositor_address,\r\n    recipient_address\r\n    \r\nFROM cleaned_fills\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND relayer_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_monad__fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:15.533501Z", "completed_at": "2025-12-26T23:48:15.552891Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:15.554528Z", "completed_at": "2025-12-26T23:48:15.970582Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.46576762199401855, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_monad__refunds", "compiled": true, "compiled_code": "-- Staging model for ExecutedRelayerRefundRoot events from Monad\r\n\r\nWITH raw_refunds AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'monad')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_chain_id,                  -- Chain ID where the refund was executed\r\n        topic_root_bundle_id,            -- Merkle root bundle identifier (groups multiple refunds)\r\n        topic_leaf_id,                   -- Leaf index in the merkle tree (identifies this specific refund batch)\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the refund\r\n        amount_to_return,                -- Total amount of capital returned in this batch\r\n        l2_token_address,                -- Token address being refunded (on Monad)\r\n        refund_amounts,                  -- Comma-separated list of individual refund amounts\r\n        refund_addresses,                -- Comma-separated list of relayer addresses receiving refunds\r\n        refund_count                     -- Number of relayers being refunded in this batch\r\n        \r\n    FROM raw.monad_logs_processed\r\n    \r\n    -- Filter: Only include rows where ExecutedRelayerRefundRoot data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0xf4ad92585b1bc117fbdd644990adf0827bc4c95baeae8a23322af807b6d0020e'\r\n        AND amount_to_return IS NOT NULL\r\n        AND l2_token_address IS NOT NULL\r\n        AND refund_count IS NOT NULL\r\n),\r\n\r\ncleaned_refunds AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS refund_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Chain ID: Which blockchain this refund was executed on\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 1 = Ethereum, 143 = Monad\r\n        -- Cast via NUMERIC first to handle decimal strings like \"42161.0\" from ETL\r\n        (topic_chain_id::NUMERIC)::BIGINT AS chain_id,\r\n        \r\n        -- Root bundle ID: Groups multiple refunds together in a merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Multiple refund batches can be grouped into one merkle root for gas efficiency\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_root_bundle_id::NUMERIC)::BIGINT AS root_bundle_id,\r\n        \r\n        -- Leaf ID: Identifies this specific refund batch within the merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Each leaf represents one batch of refunds to multiple relayers\r\n        -- Cast via NUMERIC first to handle decimal strings like \"789.0\" from ETL\r\n        (topic_leaf_id::NUMERIC)::BIGINT AS leaf_id,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was refunded)\r\n        -- ============================================================\r\n        \r\n        -- L2 token address: The token being refunded on Monad\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        -- Example: 0x754704Bc059F8C67012fEd69BC8A327a5aafb603 = USDC on Monad\r\n        l2_token_address AS refund_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was refunded)\r\n        -- ============================================================\r\n        \r\n        -- Amount to return: Total capital returned in this batch\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- This is the sum of all individual refund amounts in the batch\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        amount_to_return::NUMERIC AS total_refund_amount,\r\n        \r\n        -- Refund amounts: Individual refund amounts as comma-separated string\r\n        -- Format: \"1000000000000000000,2000000000000000000,3000000000000000000\"\r\n        -- Each value is in token's base units (e.g., wei for ETH, 6 decimals for USDC)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_amounts AS refund_amounts_string,\r\n        \r\n        -- Refund addresses: Relayer addresses receiving refunds as comma-separated string\r\n        -- Format: \"0xAAA...,0xBBB...,0xCCC...\"\r\n        -- Matches 1:1 with refund_amounts (first address gets first amount, etc.)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_addresses AS refund_addresses_string,\r\n        \r\n        -- Refund count: Number of relayers being refunded in this batch\r\n        -- Already converted by ETL to integer\r\n        -- This tells us how many individual refunds are in the arrays above\r\n        refund_count::INTEGER AS refund_count\r\n        \r\n    FROM raw_refunds\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    refund_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields (merkle tree identifiers)\r\n    chain_id,\r\n    root_bundle_id,\r\n    leaf_id,\r\n    \r\n    -- Token info\r\n    refund_token_address,\r\n    \r\n    -- Amounts\r\n    total_refund_amount,\r\n    refund_amounts_string,\r\n    refund_addresses_string,\r\n    refund_count\r\n    \r\nFROM cleaned_refunds\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE chain_id IS NOT NULL\r\n    AND refund_token_address IS NOT NULL\r\n    AND total_refund_amount IS NOT NULL\r\n    AND refund_count IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_monad__refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:15.458586Z", "completed_at": "2025-12-26T23:48:15.488503Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:15.494249Z", "completed_at": "2025-12-26T23:48:16.016391Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.5910885334014893, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_monad__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from Monad\r\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\r\n\r\nWITH raw_deposits AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'monad')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\r\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\r\n        topic_depositor,                  -- Address of the user who initiated the deposit\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the deposit\r\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\r\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\r\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\r\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\r\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\r\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\r\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\r\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\r\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\r\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\r\n        \r\n    FROM raw.monad_logs_processed\r\n    \r\n    -- Filter: Only include rows where FundsDeposited data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\r\n        AND funds_deposited_data_input_amount IS NOT NULL\r\n        AND funds_deposited_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_deposits AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        -- The ETL process may store timestamps as Unix integers or ISO strings\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS deposit_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Destination chain ID: Which blockchain the funds are being sent TO\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Depositor address: Who initiated the bridge transaction\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_depositor AS depositor_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address being deposited on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on Monad\r\n        funds_deposited_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address to receive on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on destination chain\r\n        funds_deposited_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was deposited on the origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        funds_deposited_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: Expected amount to receive on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread, but can vary with exchange rates\r\n        funds_deposited_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- TIMING INFORMATION (deadlines and quotes)\r\n        -- ============================================================\r\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\r\n        \r\n        -- Quote timestamp: When the exchange rate quote was generated\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Used to determine which exchange rate was used for the bridge\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\r\n        \r\n        -- Fill deadline: Latest timestamp by which the deposit must be filled\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- If not filled by this time, the deposit can be refunded\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\r\n        \r\n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\r\n        \r\n        -- ============================================================\r\n        -- USER & RELAYER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        funds_deposited_data_recipient AS recipient_address\r\n        \r\n        -- Exclusive relayer: Address with exclusive fill rights (if any)\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\r\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\r\n        \r\n    FROM raw_deposits\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    deposit_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    destination_chain_id,\r\n    deposit_id,\r\n    depositor_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Timing (commented out - available in schema but not included in output)\r\n    -- quote_timestamp,\r\n    -- fill_deadline,\r\n    -- exclusivity_deadline,\r\n    \r\n    -- User info\r\n    recipient_address\r\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\r\n    \r\nFROM cleaned_deposits\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND depositor_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_monad__deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:15.544978Z", "completed_at": "2025-12-26T23:48:15.566579Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:15.568063Z", "completed_at": "2025-12-26T23:48:16.048352Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.5229992866516113, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_polygon__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from Polygon\r\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\r\n\r\nWITH raw_deposits AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'polygon')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\r\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\r\n        topic_depositor,                  -- Address of the user who initiated the deposit\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the deposit\r\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\r\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\r\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\r\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\r\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\r\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\r\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\r\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\r\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\r\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\r\n        \r\n    FROM raw.polygon_logs_processed\r\n    \r\n    -- Filter: Only include rows where FundsDeposited data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\r\n        AND funds_deposited_data_input_amount IS NOT NULL\r\n        AND funds_deposited_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_deposits AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        -- The ETL process may store timestamps as Unix integers or ISO strings\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS deposit_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Destination chain ID: Which blockchain the funds are being sent TO\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Depositor address: Who initiated the bridge transaction\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_depositor AS depositor_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address being deposited on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on Polygon\r\n        funds_deposited_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address to receive on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on destination chain\r\n        funds_deposited_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was deposited on the origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        funds_deposited_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: Expected amount to receive on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread, but can vary with exchange rates\r\n        funds_deposited_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- TIMING INFORMATION (deadlines and quotes)\r\n        -- ============================================================\r\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\r\n        \r\n        -- Quote timestamp: When the exchange rate quote was generated\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Used to determine which exchange rate was used for the bridge\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\r\n        \r\n        -- Fill deadline: Latest timestamp by which the deposit must be filled\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- If not filled by this time, the deposit can be refunded\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\r\n        \r\n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\r\n        \r\n        -- ============================================================\r\n        -- USER & RELAYER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        funds_deposited_data_recipient AS recipient_address\r\n        \r\n        -- Exclusive relayer: Address with exclusive fill rights (if any)\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\r\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\r\n        \r\n    FROM raw_deposits\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    deposit_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    destination_chain_id,\r\n    deposit_id,\r\n    depositor_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Timing (commented out - available in schema but not included in output)\r\n    -- quote_timestamp,\r\n    -- fill_deadline,\r\n    -- exclusivity_deadline,\r\n    \r\n    -- User info\r\n    recipient_address\r\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\r\n    \r\nFROM cleaned_deposits\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND depositor_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_polygon__deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:15.881200Z", "completed_at": "2025-12-26T23:48:15.902793Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:15.909188Z", "completed_at": "2025-12-26T23:48:16.224267Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.34807610511779785, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_polygon__fills", "compiled": true, "compiled_code": "-- Staging model for FilledRelay events from Polygon\r\n\r\nWITH raw_fills AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'polygon')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_origin_chain_id,           -- Chain ID where the original deposit happened\r\n        topic_deposit_id,                -- Unique deposit identifier (links to deposit event)\r\n        topic_relayer,                   -- Address of the relayer who provided liquidity\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the fill\r\n        filled_relay_data_input_token,          -- Token address on origin chain\r\n        filled_relay_data_output_token,          -- Token address on destination chain\r\n        filled_relay_data_input_amount,          -- Amount sent (in origin token units)\r\n        filled_relay_data_output_amount,         -- Amount received (in destination token units)\r\n        filled_relay_data_repayment_chain_id,     -- Where relayer gets reimbursed\r\n        filled_relay_data_exclusive_relayer,     -- Address with exclusive fill rights (if any)\r\n        filled_relay_data_depositor,             -- Original user who initiated the bridge\r\n        filled_relay_data_recipient              -- Final recipient of the bridged funds\r\n        \r\n    FROM raw.polygon_logs_processed\r\n    \r\n    -- Filter: Only include rows where FilledRelay data exists\r\n    WHERE topic_0 = '0x44b559f101f8fbcc8a0ea43fa91a05a729a5ea6e14a7c75aa750374690137208'\r\n        AND filled_relay_data_input_amount IS NOT NULL\r\n        AND filled_relay_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_fills AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        \r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP can parse various formats, but we use the simplest approach\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string\r\n        END AS fill_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Origin chain ID: Which blockchain the funds came FROM\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_origin_chain_id::NUMERIC)::BIGINT AS origin_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this fill to its original deposit\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Relayer address: Who provided the liquidity\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_relayer AS relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        filled_relay_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address on the destination chain (Polygon in this case)\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was sent from origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        filled_relay_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: How much was received on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread\r\n        filled_relay_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- RELAYER & ROUTING INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Repayment chain ID: Where the relayer gets reimbursed\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Relayers front capital, then get paid back (often on a different chain)\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1.0\" from ETL\r\n        (filled_relay_data_repayment_chain_id::NUMERIC)::BIGINT AS repayment_chain_id,\r\n        \r\n        -- Exclusive relayer: If set, only this address can fill this deposit\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        filled_relay_data_exclusive_relayer AS exclusive_relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- USER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Depositor: The original user who initiated the bridge\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_depositor AS depositor_address,\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        filled_relay_data_recipient AS recipient_address\r\n        \r\n    FROM raw_fills\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    fill_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    origin_chain_id,\r\n    deposit_id,\r\n    relayer_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Relayer routing\r\n    repayment_chain_id,\r\n    exclusive_relayer_address,\r\n    \r\n    -- User info\r\n    depositor_address,\r\n    recipient_address\r\n    \r\nFROM cleaned_fills\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND relayer_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_polygon__fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:16.034432Z", "completed_at": "2025-12-26T23:48:16.053593Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:16.059961Z", "completed_at": "2025-12-26T23:48:16.361490Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.33812522888183594, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_polygon__refunds", "compiled": true, "compiled_code": "-- Staging model for ExecutedRelayerRefundRoot events from Polygon\r\n\r\nWITH raw_refunds AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'polygon')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_chain_id,                  -- Chain ID where the refund was executed\r\n        topic_root_bundle_id,            -- Merkle root bundle identifier (groups multiple refunds)\r\n        topic_leaf_id,                   -- Leaf index in the merkle tree (identifies this specific refund batch)\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the refund\r\n        amount_to_return,                -- Total amount of capital returned in this batch\r\n        l2_token_address,                -- Token address being refunded (on Polygon)\r\n        refund_amounts,                  -- Comma-separated list of individual refund amounts\r\n        refund_addresses,                -- Comma-separated list of relayer addresses receiving refunds\r\n        refund_count                     -- Number of relayers being refunded in this batch\r\n        \r\n    FROM raw.polygon_logs_processed\r\n    \r\n    -- Filter: Only include rows where ExecutedRelayerRefundRoot data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0xf4ad92585b1bc117fbdd644990adf0827bc4c95baeae8a23322af807b6d0020e'\r\n        AND amount_to_return IS NOT NULL\r\n        AND l2_token_address IS NOT NULL\r\n        AND refund_count IS NOT NULL\r\n),\r\n\r\ncleaned_refunds AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS refund_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Chain ID: Which blockchain this refund was executed on\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 1 = Ethereum, 137 = Polygon\r\n        -- Cast via NUMERIC first to handle decimal strings like \"42161.0\" from ETL\r\n        (topic_chain_id::NUMERIC)::BIGINT AS chain_id,\r\n        \r\n        -- Root bundle ID: Groups multiple refunds together in a merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Multiple refund batches can be grouped into one merkle root for gas efficiency\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_root_bundle_id::NUMERIC)::BIGINT AS root_bundle_id,\r\n        \r\n        -- Leaf ID: Identifies this specific refund batch within the merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Each leaf represents one batch of refunds to multiple relayers\r\n        -- Cast via NUMERIC first to handle decimal strings like \"789.0\" from ETL\r\n        (topic_leaf_id::NUMERIC)::BIGINT AS leaf_id,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was refunded)\r\n        -- ============================================================\r\n        \r\n        -- L2 token address: The token being refunded on Polygon\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        -- Example: 0x2791Bca1f2de4661ED88A30C99A7a9449Aa84174 = USDC on Polygon\r\n        l2_token_address AS refund_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was refunded)\r\n        -- ============================================================\r\n        \r\n        -- Amount to return: Total capital returned in this batch\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- This is the sum of all individual refund amounts in the batch\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        amount_to_return::NUMERIC AS total_refund_amount,\r\n        \r\n        -- Refund amounts: Individual refund amounts as comma-separated string\r\n        -- Format: \"1000000000000000000,2000000000000000000,3000000000000000000\"\r\n        -- Each value is in token's base units (e.g., wei for ETH, 6 decimals for USDC)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_amounts AS refund_amounts_string,\r\n        \r\n        -- Refund addresses: Relayer addresses receiving refunds as comma-separated string\r\n        -- Format: \"0xAAA...,0xBBB...,0xCCC...\"\r\n        -- Matches 1:1 with refund_amounts (first address gets first amount, etc.)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_addresses AS refund_addresses_string,\r\n        \r\n        -- Refund count: Number of relayers being refunded in this batch\r\n        -- Already converted by ETL to integer\r\n        -- This tells us how many individual refunds are in the arrays above\r\n        refund_count::INTEGER AS refund_count\r\n        \r\n    FROM raw_refunds\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    refund_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields (merkle tree identifiers)\r\n    chain_id,\r\n    root_bundle_id,\r\n    leaf_id,\r\n    \r\n    -- Token info\r\n    refund_token_address,\r\n    \r\n    -- Amounts\r\n    total_refund_amount,\r\n    refund_amounts_string,\r\n    refund_addresses_string,\r\n    refund_count\r\n    \r\nFROM cleaned_refunds\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE chain_id IS NOT NULL\r\n    AND refund_token_address IS NOT NULL\r\n    AND total_refund_amount IS NOT NULL\r\n    AND refund_count IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_polygon__refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:16.075357Z", "completed_at": "2025-12-26T23:48:16.089240Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:16.094084Z", "completed_at": "2025-12-26T23:48:16.415218Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.3480367660522461, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_unichain__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from Unichain\r\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\r\n\r\nWITH raw_deposits AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'unichain')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\r\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\r\n        topic_depositor,                  -- Address of the user who initiated the deposit\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the deposit\r\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\r\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\r\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\r\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\r\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\r\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\r\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\r\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\r\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\r\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\r\n        \r\n    FROM raw.unichain_logs_processed\r\n    \r\n    -- Filter: Only include rows where FundsDeposited data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\r\n        AND funds_deposited_data_input_amount IS NOT NULL\r\n        AND funds_deposited_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_deposits AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        -- The ETL process may store timestamps as Unix integers or ISO strings\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS deposit_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Destination chain ID: Which blockchain the funds are being sent TO\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Depositor address: Who initiated the bridge transaction\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_depositor AS depositor_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address being deposited on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on Unichain\r\n        funds_deposited_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address to receive on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on destination chain\r\n        funds_deposited_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was deposited on the origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        funds_deposited_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: Expected amount to receive on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread, but can vary with exchange rates\r\n        funds_deposited_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- TIMING INFORMATION (deadlines and quotes)\r\n        -- ============================================================\r\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\r\n        \r\n        -- Quote timestamp: When the exchange rate quote was generated\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Used to determine which exchange rate was used for the bridge\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\r\n        \r\n        -- Fill deadline: Latest timestamp by which the deposit must be filled\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- If not filled by this time, the deposit can be refunded\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\r\n        \r\n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\r\n        \r\n        -- ============================================================\r\n        -- USER & RELAYER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        funds_deposited_data_recipient AS recipient_address\r\n        \r\n        -- Exclusive relayer: Address with exclusive fill rights (if any)\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\r\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\r\n        \r\n    FROM raw_deposits\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    deposit_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    destination_chain_id,\r\n    deposit_id,\r\n    depositor_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Timing (commented out - available in schema but not included in output)\r\n    -- quote_timestamp,\r\n    -- fill_deadline,\r\n    -- exclusivity_deadline,\r\n    \r\n    -- User info\r\n    recipient_address\r\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\r\n    \r\nFROM cleaned_deposits\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND depositor_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_unichain__deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:16.119213Z", "completed_at": "2025-12-26T23:48:16.128943Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:16.130296Z", "completed_at": "2025-12-26T23:48:16.579105Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.46604228019714355, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_unichain__fills", "compiled": true, "compiled_code": "-- Staging model for FilledRelay events from Unichain\r\n\r\nWITH raw_fills AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'unichain')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_origin_chain_id,           -- Chain ID where the original deposit happened\r\n        topic_deposit_id,                -- Unique deposit identifier (links to deposit event)\r\n        topic_relayer,                   -- Address of the relayer who provided liquidity\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the fill\r\n        filled_relay_data_input_token,          -- Token address on origin chain\r\n        filled_relay_data_output_token,          -- Token address on destination chain\r\n        filled_relay_data_input_amount,          -- Amount sent (in origin token units)\r\n        filled_relay_data_output_amount,         -- Amount received (in destination token units)\r\n        filled_relay_data_repayment_chain_id,     -- Where relayer gets reimbursed\r\n        filled_relay_data_exclusive_relayer,     -- Address with exclusive fill rights (if any)\r\n        filled_relay_data_depositor,             -- Original user who initiated the bridge\r\n        filled_relay_data_recipient              -- Final recipient of the bridged funds\r\n        \r\n    FROM raw.unichain_logs_processed\r\n    \r\n    -- Filter: Only include rows where FilledRelay data exists\r\n    WHERE topic_0 = '0x44b559f101f8fbcc8a0ea43fa91a05a729a5ea6e14a7c75aa750374690137208'\r\n        AND filled_relay_data_input_amount IS NOT NULL\r\n        AND filled_relay_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_fills AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        \r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP can parse various formats, but we use the simplest approach\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string\r\n        END AS fill_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Origin chain ID: Which blockchain the funds came FROM\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_origin_chain_id::NUMERIC)::BIGINT AS origin_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this fill to its original deposit\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Relayer address: Who provided the liquidity\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_relayer AS relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        filled_relay_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address on the destination chain (Unichain in this case)\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was sent from origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        filled_relay_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: How much was received on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread\r\n        filled_relay_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- RELAYER & ROUTING INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Repayment chain ID: Where the relayer gets reimbursed\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Relayers front capital, then get paid back (often on a different chain)\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1.0\" from ETL\r\n        (filled_relay_data_repayment_chain_id::NUMERIC)::BIGINT AS repayment_chain_id,\r\n        \r\n        -- Exclusive relayer: If set, only this address can fill this deposit\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        filled_relay_data_exclusive_relayer AS exclusive_relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- USER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Depositor: The original user who initiated the bridge\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_depositor AS depositor_address,\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        filled_relay_data_recipient AS recipient_address\r\n        \r\n    FROM raw_fills\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    fill_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    origin_chain_id,\r\n    deposit_id,\r\n    relayer_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Relayer routing\r\n    repayment_chain_id,\r\n    exclusive_relayer_address,\r\n    \r\n    -- User info\r\n    depositor_address,\r\n    recipient_address\r\n    \r\nFROM cleaned_fills\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND relayer_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_unichain__fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:16.259217Z", "completed_at": "2025-12-26T23:48:16.266957Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:16.268139Z", "completed_at": "2025-12-26T23:48:16.821758Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.5696127414703369, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_unichain__refunds", "compiled": true, "compiled_code": "-- Staging model for ExecutedRelayerRefundRoot events from Unichain\r\n\r\nWITH raw_refunds AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'unichain')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_chain_id,                  -- Chain ID where the refund was executed\r\n        topic_root_bundle_id,            -- Merkle root bundle identifier (groups multiple refunds)\r\n        topic_leaf_id,                   -- Leaf index in the merkle tree (identifies this specific refund batch)\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the refund\r\n        amount_to_return,                -- Total amount of capital returned in this batch\r\n        l2_token_address,                -- Token address being refunded (on Unichain)\r\n        refund_amounts,                  -- Comma-separated list of individual refund amounts\r\n        refund_addresses,                -- Comma-separated list of relayer addresses receiving refunds\r\n        refund_count                     -- Number of relayers being refunded in this batch\r\n        \r\n    FROM raw.unichain_logs_processed\r\n    \r\n    -- Filter: Only include rows where ExecutedRelayerRefundRoot data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0xf4ad92585b1bc117fbdd644990adf0827bc4c95baeae8a23322af807b6d0020e'\r\n        AND amount_to_return IS NOT NULL\r\n        AND l2_token_address IS NOT NULL\r\n        AND refund_count IS NOT NULL\r\n),\r\n\r\ncleaned_refunds AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS refund_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Chain ID: Which blockchain this refund was executed on\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 1 = Ethereum, 130 = Unichain\r\n        -- Cast via NUMERIC first to handle decimal strings like \"42161.0\" from ETL\r\n        (topic_chain_id::NUMERIC)::BIGINT AS chain_id,\r\n        \r\n        -- Root bundle ID: Groups multiple refunds together in a merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Multiple refund batches can be grouped into one merkle root for gas efficiency\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_root_bundle_id::NUMERIC)::BIGINT AS root_bundle_id,\r\n        \r\n        -- Leaf ID: Identifies this specific refund batch within the merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Each leaf represents one batch of refunds to multiple relayers\r\n        -- Cast via NUMERIC first to handle decimal strings like \"789.0\" from ETL\r\n        (topic_leaf_id::NUMERIC)::BIGINT AS leaf_id,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was refunded)\r\n        -- ============================================================\r\n        \r\n        -- L2 token address: The token being refunded on Unichain\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        -- This is the token address on the Unichain\r\n        l2_token_address AS refund_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was refunded)\r\n        -- ============================================================\r\n        \r\n        -- Amount to return: Total capital returned in this batch\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- This is the sum of all individual refund amounts in the batch\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        amount_to_return::NUMERIC AS total_refund_amount,\r\n        \r\n        -- Refund amounts: Individual refund amounts as comma-separated string\r\n        -- Format: \"1000000000000000000,2000000000000000000,3000000000000000000\"\r\n        -- Each value is in token's base units (e.g., wei for ETH, 6 decimals for USDC)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_amounts AS refund_amounts_string,\r\n        \r\n        -- Refund addresses: Relayer addresses receiving refunds as comma-separated string\r\n        -- Format: \"0xAAA...,0xBBB...,0xCCC...\"\r\n        -- Matches 1:1 with refund_amounts (first address gets first amount, etc.)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_addresses AS refund_addresses_string,\r\n        \r\n        -- Refund count: Number of relayers being refunded in this batch\r\n        -- Already converted by ETL to integer\r\n        -- This tells us how many individual refunds are in the arrays above\r\n        refund_count::INTEGER AS refund_count\r\n        \r\n    FROM raw_refunds\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    refund_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields (merkle tree identifiers)\r\n    chain_id,\r\n    root_bundle_id,\r\n    leaf_id,\r\n    \r\n    -- Token info\r\n    refund_token_address,\r\n    \r\n    -- Amounts\r\n    total_refund_amount,\r\n    refund_amounts_string,\r\n    refund_addresses_string,\r\n    refund_count\r\n    \r\nFROM cleaned_refunds\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE chain_id IS NOT NULL\r\n    AND refund_token_address IS NOT NULL\r\n    AND total_refund_amount IS NOT NULL\r\n    AND refund_count IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_unichain__refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:16.430299Z", "completed_at": "2025-12-26T23:48:16.443417Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:16.444693Z", "completed_at": "2025-12-26T23:48:16.816076Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.40817832946777344, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_worldchain__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from Worldchain\r\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\r\n\r\nWITH raw_deposits AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'worldchain')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\r\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\r\n        topic_depositor,                  -- Address of the user who initiated the deposit\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the deposit\r\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\r\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\r\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\r\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\r\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\r\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\r\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\r\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\r\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\r\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\r\n        \r\n    FROM raw.worldchain_logs_processed\r\n    \r\n    -- Filter: Only include rows where FundsDeposited data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\r\n        AND funds_deposited_data_input_amount IS NOT NULL\r\n        AND funds_deposited_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_deposits AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        -- The ETL process may store timestamps as Unix integers or ISO strings\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS deposit_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Destination chain ID: Which blockchain the funds are being sent TO\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Depositor address: Who initiated the bridge transaction\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_depositor AS depositor_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address being deposited on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on Worldchain\r\n        funds_deposited_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address to receive on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: Token address on destination chain\r\n        funds_deposited_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was deposited)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was deposited on the origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        funds_deposited_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: Expected amount to receive on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread, but can vary with exchange rates\r\n        funds_deposited_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- TIMING INFORMATION (deadlines and quotes)\r\n        -- ============================================================\r\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\r\n        \r\n        -- Quote timestamp: When the exchange rate quote was generated\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Used to determine which exchange rate was used for the bridge\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\r\n        \r\n        -- Fill deadline: Latest timestamp by which the deposit must be filled\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- If not filled by this time, the deposit can be refunded\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\r\n        \r\n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\r\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\r\n        \r\n        -- ============================================================\r\n        -- USER & RELAYER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        funds_deposited_data_recipient AS recipient_address\r\n        \r\n        -- Exclusive relayer: Address with exclusive fill rights (if any)\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\r\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\r\n        \r\n    FROM raw_deposits\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    deposit_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    destination_chain_id,\r\n    deposit_id,\r\n    depositor_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Timing (commented out - available in schema but not included in output)\r\n    -- quote_timestamp,\r\n    -- fill_deadline,\r\n    -- exclusivity_deadline,\r\n    \r\n    -- User info\r\n    recipient_address\r\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\r\n    \r\nFROM cleaned_deposits\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND depositor_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_worldchain__deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:16.469887Z", "completed_at": "2025-12-26T23:48:16.479789Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:16.481445Z", "completed_at": "2025-12-26T23:48:16.884451Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.4255664348602295, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_worldchain__fills", "compiled": true, "compiled_code": "-- Staging model for FilledRelay events from Worldchain\r\n\r\nWITH raw_fills AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'worldchain')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_origin_chain_id,           -- Chain ID where the original deposit happened\r\n        topic_deposit_id,                -- Unique deposit identifier (links to deposit event)\r\n        topic_relayer,                   -- Address of the relayer who provided liquidity\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the fill\r\n        filled_relay_data_input_token,          -- Token address on origin chain\r\n        filled_relay_data_output_token,          -- Token address on destination chain\r\n        filled_relay_data_input_amount,          -- Amount sent (in origin token units)\r\n        filled_relay_data_output_amount,         -- Amount received (in destination token units)\r\n        filled_relay_data_repayment_chain_id,     -- Where relayer gets reimbursed\r\n        filled_relay_data_exclusive_relayer,     -- Address with exclusive fill rights (if any)\r\n        filled_relay_data_depositor,             -- Original user who initiated the bridge\r\n        filled_relay_data_recipient              -- Final recipient of the bridged funds\r\n        \r\n    FROM raw.worldchain_logs_processed\r\n    \r\n    -- Filter: Only include rows where FilledRelay data exists\r\n    WHERE topic_0 = '0x44b559f101f8fbcc8a0ea43fa91a05a729a5ea6e14a7c75aa750374690137208'\r\n        AND filled_relay_data_input_amount IS NOT NULL\r\n        AND filled_relay_data_output_amount IS NOT NULL\r\n),\r\n\r\ncleaned_fills AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        \r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP can parse various formats, but we use the simplest approach\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string\r\n        END AS fill_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Origin chain ID: Which blockchain the funds came FROM\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 1 = Ethereum, 42161 = Arbitrum, 8453 = Base\r\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\r\n        (topic_origin_chain_id::NUMERIC)::BIGINT AS origin_chain_id,\r\n        \r\n        -- Deposit ID: Unique identifier linking this fill to its original deposit\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- This is the KEY that connects deposits \u2194 fills across chains\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\r\n        \r\n        -- Relayer address: Who provided the liquidity\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        topic_relayer AS relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input token: The token address on the origin chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\r\n        filled_relay_data_input_token AS input_token_address,\r\n        \r\n        -- Output token: The token address on the destination chain (Worldchain in this case)\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_output_token AS output_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was bridged)\r\n        -- ============================================================\r\n        \r\n        -- Input amount: How much was sent from origin chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        filled_relay_data_input_amount::NUMERIC AS input_amount,\r\n        \r\n        -- Output amount: How much was received on destination chain\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Usually slightly less than input due to fees/spread\r\n        filled_relay_data_output_amount::NUMERIC AS output_amount,\r\n        \r\n        -- ============================================================\r\n        -- RELAYER & ROUTING INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Repayment chain ID: Where the relayer gets reimbursed\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- Relayers front capital, then get paid back (often on a different chain)\r\n        -- Cast via NUMERIC first to handle decimal strings like \"1.0\" from ETL\r\n        (filled_relay_data_repayment_chain_id::NUMERIC)::BIGINT AS repayment_chain_id,\r\n        \r\n        -- Exclusive relayer: If set, only this address can fill this deposit\r\n        -- Already decoded by ETL to proper address format\r\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\r\n        filled_relay_data_exclusive_relayer AS exclusive_relayer_address,\r\n        \r\n        -- ============================================================\r\n        -- USER INFORMATION\r\n        -- ============================================================\r\n        \r\n        -- Depositor: The original user who initiated the bridge\r\n        -- Already decoded by ETL to proper address format\r\n        filled_relay_data_depositor AS depositor_address,\r\n        \r\n        -- Recipient: Who receives the funds on the destination chain\r\n        -- Already decoded by ETL to proper address format\r\n        -- Usually the same as depositor, but can be different (gift/transfer)\r\n        filled_relay_data_recipient AS recipient_address\r\n        \r\n    FROM raw_fills\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    fill_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields\r\n    origin_chain_id,\r\n    deposit_id,\r\n    relayer_address,\r\n    \r\n    -- Token info\r\n    input_token_address,\r\n    output_token_address,\r\n    \r\n    -- Amounts\r\n    input_amount,\r\n    output_amount,\r\n    \r\n    -- Relayer routing\r\n    repayment_chain_id,\r\n    exclusive_relayer_address,\r\n    \r\n    -- User info\r\n    depositor_address,\r\n    recipient_address\r\n    \r\nFROM cleaned_fills\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE deposit_id IS NOT NULL\r\n    AND relayer_address IS NOT NULL\r\n    AND input_token_address IS NOT NULL\r\n    AND output_token_address IS NOT NULL\r\n    AND input_amount IS NOT NULL\r\n    AND output_amount IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_worldchain__fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:16.653580Z", "completed_at": "2025-12-26T23:48:16.663417Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:16.665466Z", "completed_at": "2025-12-26T23:48:16.988028Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.33786678314208984, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_worldchain__refunds", "compiled": true, "compiled_code": "-- Staging model for ExecutedRelayerRefundRoot events from Worldchain\r\n\r\nWITH raw_refunds AS (\r\n\r\n    SELECT\r\n        -- Core event metadata - these identify WHEN and WHERE the event happened\r\n        timestamp_datetime,              -- When the event occurred (from blockchain)\r\n        transactionHash,                 -- Unique transaction identifier\r\n        blockchain,                      -- Which blockchain (should be 'worldchain')\r\n        source_file,                     -- Which source file this came from (for lineage)\r\n        \r\n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\r\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\r\n        topic_chain_id,                  -- Chain ID where the refund was executed\r\n        topic_root_bundle_id,            -- Merkle root bundle identifier (groups multiple refunds)\r\n        topic_leaf_id,                   -- Leaf index in the merkle tree (identifies this specific refund batch)\r\n        \r\n        -- Non-indexed fields from the event's data field\r\n        -- These are the actual business data about the refund\r\n        amount_to_return,                -- Total amount of capital returned in this batch\r\n        l2_token_address,                -- Token address being refunded (on Worldchain)\r\n        refund_amounts,                  -- Comma-separated list of individual refund amounts\r\n        refund_addresses,                -- Comma-separated list of relayer addresses receiving refunds\r\n        refund_count                     -- Number of relayers being refunded in this batch\r\n        \r\n    FROM raw.worldchain_logs_processed\r\n    \r\n    -- Filter: Only include rows where ExecutedRelayerRefundRoot data exists\r\n    -- Topic_0 is the event signature hash that identifies the event type\r\n    WHERE topic_0 = '0xf4ad92585b1bc117fbdd644990adf0827bc4c95baeae8a23322af807b6d0020e'\r\n        AND amount_to_return IS NOT NULL\r\n        AND l2_token_address IS NOT NULL\r\n        AND refund_count IS NOT NULL\r\n),\r\n\r\ncleaned_refunds AS (\r\n    SELECT\r\n        \r\n        -- Timestamp: Convert text to proper timestamp type\r\n        CASE \r\n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\r\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\r\n            ELSE \r\n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\r\n        END AS refund_timestamp,\r\n        \r\n        transactionHash AS transaction_hash,\r\n        blockchain,\r\n        source_file,\r\n        \r\n        -- ============================================================\r\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\r\n        -- ============================================================\r\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\r\n        \r\n        -- Chain ID: Which blockchain this refund was executed on\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Example: 42161 = Arbitrum, 1 = Ethereum, 480 = Worldchain\r\n        -- Cast via NUMERIC first to handle decimal strings like \"42161.0\" from ETL\r\n        (topic_chain_id::NUMERIC)::BIGINT AS chain_id,\r\n        \r\n        -- Root bundle ID: Groups multiple refunds together in a merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Multiple refund batches can be grouped into one merkle root for gas efficiency\r\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\r\n        (topic_root_bundle_id::NUMERIC)::BIGINT AS root_bundle_id,\r\n        \r\n        -- Leaf ID: Identifies this specific refund batch within the merkle tree\r\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\r\n        -- Each leaf represents one batch of refunds to multiple relayers\r\n        -- Cast via NUMERIC first to handle decimal strings like \"789.0\" from ETL\r\n        (topic_leaf_id::NUMERIC)::BIGINT AS leaf_id,\r\n        \r\n        -- ============================================================\r\n        -- TOKEN INFORMATION (what was refunded)\r\n        -- ============================================================\r\n        \r\n        -- L2 token address: The token being refunded on Worldchain\r\n        -- Already decoded by ETL to proper address format (0x...)\r\n        -- This is the token address on the Worldchain\r\n        l2_token_address AS refund_token_address,\r\n        \r\n        -- ============================================================\r\n        -- AMOUNT INFORMATION (how much was refunded)\r\n        -- ============================================================\r\n        \r\n        -- Amount to return: Total capital returned in this batch\r\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\r\n        -- This is the sum of all individual refund amounts in the batch\r\n        -- Stored as NUMERIC to handle large token amounts (18 decimals)\r\n        amount_to_return::NUMERIC AS total_refund_amount,\r\n        \r\n        -- Refund amounts: Individual refund amounts as comma-separated string\r\n        -- Format: \"1000000000000000000,2000000000000000000,3000000000000000000\"\r\n        -- Each value is in token's base units (e.g., wei for ETH, 6 decimals for USDC)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_amounts AS refund_amounts_string,\r\n        \r\n        -- Refund addresses: Relayer addresses receiving refunds as comma-separated string\r\n        -- Format: \"0xAAA...,0xBBB...,0xCCC...\"\r\n        -- Matches 1:1 with refund_amounts (first address gets first amount, etc.)\r\n        -- This is a comma-separated string because the ETL processes dynamic arrays\r\n        refund_addresses AS refund_addresses_string,\r\n        \r\n        -- Refund count: Number of relayers being refunded in this batch\r\n        -- Already converted by ETL to integer\r\n        -- This tells us how many individual refunds are in the arrays above\r\n        refund_count::INTEGER AS refund_count\r\n        \r\n    FROM raw_refunds\r\n)\r\n\r\n-- Final SELECT: Add any computed fields and ensure data quality\r\nSELECT\r\n    -- Event identity\r\n    refund_timestamp,\r\n    transaction_hash,\r\n    blockchain,\r\n    source_file,\r\n    \r\n    -- Indexed fields (merkle tree identifiers)\r\n    chain_id,\r\n    root_bundle_id,\r\n    leaf_id,\r\n    \r\n    -- Token info\r\n    refund_token_address,\r\n    \r\n    -- Amounts\r\n    total_refund_amount,\r\n    refund_amounts_string,\r\n    refund_addresses_string,\r\n    refund_count\r\n    \r\nFROM cleaned_refunds\r\n\r\n-- Data quality: Only include rows with essential fields populated\r\nWHERE chain_id IS NOT NULL\r\n    AND refund_token_address IS NOT NULL\r\n    AND total_refund_amount IS NOT NULL\r\n    AND refund_count IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_worldchain__refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:16.874761Z", "completed_at": "2025-12-26T23:48:16.908784Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:16.911683Z", "completed_at": "2025-12-26T23:48:17.071785Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.20264935493469238, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.int_unified_deposits", "compiled": true, "compiled_code": "-- int_unified_deposits.sql\n-- PURPOSE: Combine deposits from ALL chains into ONE table\n-- WHY: Right now deposits are separate per chain. We need them unified to track cross-chain flows.\n\n\n\n-- Each CTE selects from a chain's staging model and adds the origin chain ID\nWITH arbitrum_deposits AS (\n    SELECT \n        deposit_timestamp,\n        transaction_hash,\n        42161 AS origin_chain_id,  -- Arbitrum's chain ID\n        destination_chain_id,\n        deposit_id,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_arbitrum__deposits\"\n),\n\nethereum_deposits AS (\n    SELECT \n        deposit_timestamp,\n        transaction_hash,\n        1 AS origin_chain_id,  -- Ethereum's chain ID\n        destination_chain_id,\n        deposit_id,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_ethereum__deposits\"\n),\n\npolygon_deposits AS (\n    SELECT \n        deposit_timestamp,\n        transaction_hash,\n        137 AS origin_chain_id,  -- Polygon's chain ID\n        destination_chain_id,\n        deposit_id,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_polygon__deposits\"\n),\n\nlinea_deposits AS (\n    SELECT \n        deposit_timestamp,\n        transaction_hash,\n        59144 AS origin_chain_id,  -- Linea's chain ID\n        destination_chain_id,\n        deposit_id,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_linea__deposits\"\n),\n\nworldchain_deposits AS (\n    SELECT \n        deposit_timestamp,\n        transaction_hash,\n        480 AS origin_chain_id,  -- WorldChain's chain ID\n        destination_chain_id,\n        deposit_id,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_worldchain__deposits\"\n),\n\nunichain_deposits AS (\n    SELECT \n        deposit_timestamp,\n        transaction_hash,\n        130 AS origin_chain_id,  -- Unichain's chain ID\n        destination_chain_id,\n        deposit_id,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_unichain__deposits\"\n),\n\nhyperevm_deposits AS (\n    SELECT \n        deposit_timestamp,\n        transaction_hash,\n        999 AS origin_chain_id,  -- HyperEVM's chain ID\n        destination_chain_id,\n        deposit_id,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_hyperevm__deposits\"\n),\n\nmonad_deposits AS (\n    SELECT \n        deposit_timestamp,\n        transaction_hash,\n        140 AS origin_chain_id,  -- Monad's chain ID\n        destination_chain_id,\n        deposit_id,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_monad__deposits\"\n)\n\n-- UNION ALL: Stack all deposits from all chains into one table\nSELECT * FROM arbitrum_deposits\nUNION ALL\nSELECT * FROM ethereum_deposits\nUNION ALL\nSELECT * FROM polygon_deposits\nUNION ALL\nSELECT * FROM linea_deposits\nUNION ALL\nSELECT * FROM worldchain_deposits\nUNION ALL\nSELECT * FROM unichain_deposits\nUNION ALL\nSELECT * FROM hyperevm_deposits\nUNION ALL\nSELECT * FROM monad_deposits", "relation_name": "\"across_analytics\".\"dbt_intermediate\".\"int_unified_deposits\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:18.908443Z", "completed_at": "2025-12-26T23:48:18.925980Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:18.927329Z", "completed_at": "2025-12-26T23:48:19.148198Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.24817395210266113, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.int_unified_refunds", "compiled": true, "compiled_code": "-- int_unified_refunds.sql\n-- PURPOSE: Combine refunds from ALL chains into ONE table\n-- WHY: Refunds = capital returning to relayers. Tracks when relayers get paid back.\n\n\n\n-- Each CTE selects from a chain's staging model\nWITH arbitrum_refunds AS (\n    SELECT \n        refund_timestamp,\n        transaction_hash,\n        chain_id,\n        root_bundle_id,\n        leaf_id,\n        refund_token_address,\n        total_refund_amount,\n        refund_addresses_string,\n        refund_amounts_string,\n        refund_count,\n        'arbitrum' AS source_blockchain\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_arbitrum__refunds\"\n),\n\nethereum_refunds AS (\n    SELECT \n        refund_timestamp,\n        transaction_hash,\n        chain_id,\n        root_bundle_id,\n        leaf_id,\n        refund_token_address,\n        total_refund_amount,\n        refund_addresses_string,\n        refund_amounts_string,\n        refund_count,\n        'ethereum' AS source_blockchain\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_ethereum__refunds\"\n),\n\npolygon_refunds AS (\n    SELECT \n        refund_timestamp,\n        transaction_hash,\n        chain_id,\n        root_bundle_id,\n        leaf_id,\n        refund_token_address,\n        total_refund_amount,\n        refund_addresses_string,\n        refund_amounts_string,\n        refund_count,\n        'polygon' AS source_blockchain\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_polygon__refunds\"\n),\n\nlinea_refunds AS (\n    SELECT \n        refund_timestamp,\n        transaction_hash,\n        chain_id,\n        root_bundle_id,\n        leaf_id,\n        refund_token_address,\n        total_refund_amount,\n        refund_addresses_string,\n        refund_amounts_string,\n        refund_count,\n        'linea' AS source_blockchain\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_linea__refunds\"\n),\n\nworldchain_refunds AS (\n    SELECT \n        refund_timestamp,\n        transaction_hash,\n        chain_id,\n        root_bundle_id,\n        leaf_id,\n        refund_token_address,\n        total_refund_amount,\n        refund_addresses_string,\n        refund_amounts_string,\n        refund_count,\n        'worldchain' AS source_blockchain\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_worldchain__refunds\"\n),\n\nunichain_refunds AS (\n    SELECT \n        refund_timestamp,\n        transaction_hash,\n        chain_id,\n        root_bundle_id,\n        leaf_id,\n        refund_token_address,\n        total_refund_amount,\n        refund_addresses_string,\n        refund_amounts_string,\n        refund_count,\n        'unichain' AS source_blockchain\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_unichain__refunds\"\n),\n\nhyperevm_refunds AS (\n    SELECT \n        refund_timestamp,\n        transaction_hash,\n        chain_id,\n        root_bundle_id,\n        leaf_id,\n        refund_token_address,\n        total_refund_amount,\n        refund_addresses_string,\n        refund_amounts_string,\n        refund_count,\n        'hyperevm' AS source_blockchain\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_hyperevm__refunds\"\n),\n\nmonad_refunds AS (\n    SELECT \n        refund_timestamp,\n        transaction_hash,\n        chain_id,\n        root_bundle_id,\n        leaf_id,\n        refund_token_address,\n        total_refund_amount,\n        refund_addresses_string,\n        refund_amounts_string,\n        refund_count,\n        'monad' AS source_blockchain\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_monad__refunds\"\n)\n\n-- UNION ALL: Stack all refunds from all chains\nSELECT * FROM arbitrum_refunds\nUNION ALL\nSELECT * FROM ethereum_refunds\nUNION ALL\nSELECT * FROM polygon_refunds\nUNION ALL\nSELECT * FROM linea_refunds\nUNION ALL\nSELECT * FROM worldchain_refunds\nUNION ALL\nSELECT * FROM unichain_refunds\nUNION ALL\nSELECT * FROM hyperevm_refunds\nUNION ALL\nSELECT * FROM monad_refunds", "relation_name": "\"across_analytics\".\"dbt_intermediate\".\"int_unified_refunds\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:18.904630Z", "completed_at": "2025-12-26T23:48:18.942963Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:18.944609Z", "completed_at": "2025-12-26T23:48:19.171001Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.2702758312225342, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.int_unified_fills", "compiled": true, "compiled_code": "-- int_unified_fills.sql\n-- PURPOSE: Combine fills from ALL chains into ONE table\n-- WHY: Fills happen on the DESTINATION chain. We need to see all fills to match with deposits.\n\n\n\n-- Each CTE selects from a chain's staging model and adds the destination chain ID\nWITH arbitrum_fills AS (\n    SELECT \n        fill_timestamp,\n        transaction_hash,\n        origin_chain_id,\n        42161 AS destination_chain_id,  -- Fill happened ON Arbitrum\n        deposit_id,\n        relayer_address,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount,\n        repayment_chain_id\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_arbitrum__fills\"\n),\n\nethereum_fills AS (\n    SELECT \n        fill_timestamp,\n        transaction_hash,\n        origin_chain_id,\n        1 AS destination_chain_id,  -- Fill happened ON Ethereum\n        deposit_id,\n        relayer_address,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount,\n        repayment_chain_id\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_ethereum__fills\"\n),\n\npolygon_fills AS (\n    SELECT \n        fill_timestamp,\n        transaction_hash,\n        origin_chain_id,\n        137 AS destination_chain_id,  -- Fill happened ON Polygon\n        deposit_id,\n        relayer_address,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount,\n        repayment_chain_id\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_polygon__fills\"\n),\n\nlinea_fills AS (\n    SELECT \n        fill_timestamp,\n        transaction_hash,\n        origin_chain_id,\n        59144 AS destination_chain_id,  -- Fill happened ON Linea\n        deposit_id,\n        relayer_address,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount,\n        repayment_chain_id\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_linea__fills\"\n),\n\nworldchain_fills AS (\n    SELECT \n        fill_timestamp,\n        transaction_hash,\n        origin_chain_id,\n        480 AS destination_chain_id,  -- Fill happened ON WorldChain\n        deposit_id,\n        relayer_address,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount,\n        repayment_chain_id\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_worldchain__fills\"\n),\n\nunichain_fills AS (\n    SELECT \n        fill_timestamp,\n        transaction_hash,\n        origin_chain_id,\n        130 AS destination_chain_id,  -- Fill happened ON Unichain\n        deposit_id,\n        relayer_address,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount,\n        repayment_chain_id\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_unichain__fills\"\n),\n\nhyperevm_fills AS (\n    SELECT \n        fill_timestamp,\n        transaction_hash,\n        origin_chain_id,\n        999 AS destination_chain_id,  -- Fill happened ON HyperEVM\n        deposit_id,\n        relayer_address,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount,\n        repayment_chain_id\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_hyperevm__fills\"\n),\n\nmonad_fills AS (\n    SELECT \n        fill_timestamp,\n        transaction_hash,\n        origin_chain_id,\n        140 AS destination_chain_id,  -- Fill happened ON Monad\n        deposit_id,\n        relayer_address,\n        depositor_address,\n        recipient_address,\n        input_token_address,\n        output_token_address,\n        input_amount,\n        output_amount,\n        repayment_chain_id\n    FROM \"across_analytics\".\"dbt_staging\".\"stg_monad__fills\"\n)\n\n-- UNION ALL: Stack all fills from all chains into one table\nSELECT * FROM arbitrum_fills\nUNION ALL\nSELECT * FROM ethereum_fills\nUNION ALL\nSELECT * FROM polygon_fills\nUNION ALL\nSELECT * FROM linea_fills\nUNION ALL\nSELECT * FROM worldchain_fills\nUNION ALL\nSELECT * FROM unichain_fills\nUNION ALL\nSELECT * FROM hyperevm_fills\nUNION ALL\nSELECT * FROM monad_fills", "relation_name": "\"across_analytics\".\"dbt_intermediate\".\"int_unified_fills\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-26T23:48:19.183699Z", "completed_at": "2025-12-26T23:48:19.190138Z"}, {"name": "execute", "started_at": "2025-12-26T23:48:19.193529Z", "completed_at": "2025-12-26T23:48:19.346615Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.16626882553100586, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.int_deposit_fill_matching", "compiled": true, "compiled_code": "-- int_deposit_fill_matching.sql\n-- PURPOSE: Match every deposit to its fill (if it exists)\n-- WHY: This is the CORE model - connects money leaving one chain to money arriving on another.\n-- \n-- HOW IT WORKS:\n-- 1. User deposits on Chain A \u2192 creates deposit_id\n-- 2. Relayer fills on Chain B \u2192 same deposit_id\n-- 3. We JOIN on deposit_id + origin/destination chain match\n-- 4. Unfilled deposits = rows with NULL fill (stuck capital)\n\n\n\nWITH deposits AS (\n    SELECT * FROM \"across_analytics\".\"dbt_intermediate\".\"int_unified_deposits\"\n),\n\nfills AS (\n    SELECT * FROM \"across_analytics\".\"dbt_intermediate\".\"int_unified_fills\"\n),\n\n-- JOIN deposits to fills on deposit_id + chain matching\nmatched AS (\n    SELECT\n        -- === DEPOSIT INFO (Origin side) ===\n        d.deposit_timestamp,\n        d.transaction_hash AS deposit_tx_hash,\n        d.origin_chain_id,\n        d.destination_chain_id,\n        d.deposit_id,\n        d.depositor_address,\n        d.recipient_address AS deposit_recipient,\n        d.input_token_address AS deposit_token,\n        d.input_amount AS deposit_amount,\n        d.output_amount AS expected_output_amount,\n        \n        -- === FILL INFO (Destination side) ===\n        f.fill_timestamp,\n        f.transaction_hash AS fill_tx_hash,\n        f.relayer_address,\n        f.output_token_address AS fill_token,\n        f.output_amount AS actual_output_amount,\n        f.repayment_chain_id,\n        \n        -- === COMPUTED FIELDS ===\n        -- Fill latency: How long did it take to fill? (in seconds)\n        EXTRACT(EPOCH FROM (f.fill_timestamp - d.deposit_timestamp)) AS fill_latency_seconds,\n        \n        -- Is this deposit filled?\n        CASE WHEN f.deposit_id IS NOT NULL THEN TRUE ELSE FALSE END AS is_filled,\n        \n        -- Slippage: Difference between expected and actual output\n        CASE \n            WHEN f.output_amount IS NOT NULL AND d.output_amount > 0 \n            THEN (d.output_amount - f.output_amount) / d.output_amount * 100\n            ELSE NULL \n        END AS slippage_percent\n\n    FROM deposits d\n    \n    -- LEFT JOIN: Keep ALL deposits, even unfilled ones\n    LEFT JOIN fills f \n        ON d.deposit_id = f.deposit_id\n        AND d.origin_chain_id = f.origin_chain_id  -- Must match origin\n        AND d.destination_chain_id = f.destination_chain_id  -- Must match destination\n)\n\nSELECT\n    -- Identity\n    deposit_timestamp,\n    deposit_tx_hash,\n    origin_chain_id,\n    destination_chain_id,\n    deposit_id,\n    \n    -- Deposit details\n    depositor_address,\n    deposit_recipient,\n    deposit_token,\n    deposit_amount,\n    expected_output_amount,\n    \n    -- Fill details (NULL if unfilled)\n    fill_timestamp,\n    fill_tx_hash,\n    relayer_address,\n    fill_token,\n    actual_output_amount,\n    repayment_chain_id,\n    \n    -- Metrics\n    fill_latency_seconds,\n    is_filled,\n    slippage_percent,\n    \n    -- Route identifier (for aggregations)\n    origin_chain_id || '_' || destination_chain_id AS route_id\n\nFROM matched", "relation_name": "\"across_analytics\".\"dbt_intermediate\".\"int_deposit_fill_matching\"", "batch_results": null}], "elapsed_time": 6.412261962890625, "args": {"vars": {}, "empty": false, "require_yaml_configuration_for_mf_time_spines": false, "profiles_dir": "C:\\Users\\Longin\\.dbt", "favor_state": false, "invocation_command": "dbt run --full-refresh", "log_level_file": "debug", "full_refresh": true, "partial_parse_file_diff": true, "skip_nodes_if_on_run_start_fails": false, "log_format": "default", "use_fast_test_edges": false, "require_explicit_package_overrides_for_builtin_materializations": true, "version_check": true, "static_parser": true, "defer": false, "require_batched_execution_for_custom_microbatch_strategy": false, "print": true, "show_resource_report": false, "validate_macro_args": false, "quiet": false, "send_anonymous_usage_stats": true, "source_freshness_run_project_hooks": true, "upload_to_artifacts_ingest_api": false, "populate_cache": true, "use_colors_file": true, "state_modified_compare_vars": false, "require_all_warnings_handled_by_warn_error": false, "printer_width": 80, "warn_error_options": {"error": [], "warn": [], "silence": []}, "indirect_selection": "eager", "partial_parse": true, "require_nested_cumulative_type_params": false, "require_resource_names_without_spaces": true, "cache_selected_only": false, "use_colors": true, "project_dir": "C:\\Users\\Longin\\Desktop\\Projects\\across_analytics", "introspect": true, "select": [], "log_path": "C:\\Users\\Longin\\Desktop\\Projects\\across_analytics\\logs", "state_modified_compare_more_unrendered_values": false, "log_file_max_bytes": 10485760, "macro_debugging": false, "show_all_deprecations": false, "strict_mode": false, "log_format_file": "debug", "log_level": "info", "require_generic_test_arguments_property": true, "write_json": true, "which": "run", "exclude": []}}