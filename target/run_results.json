{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.10.15", "generated_at": "2025-12-27T13:50:43.942219Z", "invocation_id": "e828c5e1-5eab-448c-9581-dc39f4a18ad9", "invocation_started_at": "2025-12-27T13:50:38.837335Z", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-27T13:50:43.452996Z", "completed_at": "2025-12-27T13:50:43.472633Z"}, {"name": "execute", "started_at": "2025-12-27T13:50:43.475844Z", "completed_at": "2025-12-27T13:50:43.779213Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.32865452766418457, "adapter_response": {"_message": "CREATE VIEW", "code": "CREATE VIEW", "rows_affected": -1}, "message": "CREATE VIEW", "failures": null, "unique_id": "model.across_analytics.stg_arbitrum__deposits", "compiled": true, "compiled_code": "-- Staging model for FundsDeposited events from Arbitrum\n-- This model extracts deposit events where users initiate cross-chain bridge transactions\n\nWITH raw_deposits AS (\n\n    SELECT\n        -- Core event metadata - these identify WHEN and WHERE the event happened\n        timestamp_datetime,              -- When the event occurred (from blockchain)\n        transactionHash,                 -- Unique transaction identifier\n        blockchain,                      -- Which blockchain (should be 'arbitrum')\n        source_file,                     -- Which source file this came from (for lineage)\n        \n        -- Indexed fields from topics (these are searchable/filterable in blockchain)\n        -- Topics are like \"indexed columns\" in SQL - they're stored separately for fast queries\n        topic_destination_chain_id,      -- Chain ID where the funds are being sent TO\n        topic_deposit_id,                -- Unique deposit identifier (links deposits to fills)\n        topic_depositor,                  -- Address of the user who initiated the deposit\n        \n        -- Non-indexed fields from the event's data field\n        -- These are the actual business data about the deposit\n        funds_deposited_data_input_token,          -- Token address being deposited (on origin chain)\n        funds_deposited_data_output_token,         -- Token address to receive (on destination chain)\n        funds_deposited_data_input_amount,          -- Amount deposited (in input token units)\n        funds_deposited_data_output_amount,         -- Expected amount to receive (in output token units)\n        funds_deposited_data_recipient             -- Final recipient of the bridged funds\n        -- Optional fields: Not required for capital flow analysis, commented out in database schema\n        -- funds_deposited_data_quote_timestamp,       -- When the exchange rate quote was generated\n        -- funds_deposited_data_fill_deadline,         -- Deadline by which the deposit must be filled\n        -- funds_deposited_data_exclusivity_deadline,  -- Deadline for exclusive relayer rights\n        -- funds_deposited_data_exclusive_relayer      -- Address with exclusive fill rights (if any)\n        \n    FROM raw.arbitrum_logs_processed\n    \n    -- Filter: Only include rows where FundsDeposited data exists\n    -- Topic_0 is the event signature hash that identifies the event type\n    WHERE topic_0 = '0x32ed1a409ef04c7b0227189c3a103dc5ac10e775a15b785dcc510201f7c25ad3'\n        AND funds_deposited_data_input_amount IS NOT NULL\n        AND funds_deposited_data_output_amount IS NOT NULL\n),\n\n-- Uses the get_token_decimals macro which filters token_metadata seed by chain\ntoken_decimals AS (\n    \n    SELECT \n        LOWER(token_address) AS token_address,\n        token_symbol,\n        decimals\n    FROM \"across_analytics\".\"dbt\".\"token_metadata\"\n    WHERE chain = 'arbitrum'\n\n),\n\ncleaned_deposits AS (\n    SELECT\n        \n        -- Timestamp: Convert text to proper timestamp type\n        -- The ETL process may store timestamps as Unix integers or ISO strings\n        CASE \n            WHEN timestamp_datetime ~ '^\\d+$' THEN          -- If it's pure digits, treat as Unix timestamp (seconds since 1970-01-01)\n                TO_TIMESTAMP(timestamp_datetime::BIGINT)    -- PostgreSQL's TO_TIMESTAMP converts Unix seconds to timestamp\n            ELSE \n                timestamp_datetime::TIMESTAMP               -- Otherwise, try to parse as ISO format string (e.g., \"2025-12-03 10:30:00\")\n        END AS deposit_timestamp,\n        \n        transactionHash AS transaction_hash,\n        blockchain,\n        source_file,\n        \n        -- ============================================================\n        -- INDEXED FIELDS (from topics) - Already decoded by ETL\n        -- ============================================================\n        -- These come from the event's \"topics\" array, which is indexed for fast blockchain queries\n        \n        -- Destination chain ID: Which blockchain the funds are being sent TO\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\n        -- Example: 1 = Ethereum, 8453 = Base, 137 = Polygon\n        -- Cast via NUMERIC first to handle decimal strings like \"8453.0\" from ETL\n        (topic_destination_chain_id::NUMERIC)::BIGINT AS destination_chain_id,\n        \n        -- Deposit ID: Unique identifier linking this deposit to its fill(s)\n        -- Already converted by ETL from hex to integer (stored as text in raw table)\n        -- This is the KEY that connects deposits \u2194 fills across chains\n        -- Cast via NUMERIC first to handle decimal strings like \"12345.0\" from ETL\n        (topic_deposit_id::NUMERIC)::BIGINT AS deposit_id,\n        \n        -- Depositor address: Who initiated the bridge transaction\n        -- Already decoded by ETL to proper address format (0x...)\n        topic_depositor AS depositor_address,\n        \n        -- ============================================================\n        -- TOKEN INFORMATION (what was deposited)\n        -- ============================================================\n        \n        -- Input token: The token address being deposited on the origin chain\n        -- Already decoded by ETL to proper address format\n        -- Example: 0xaf88d065aC88dCc5619a6eeFdD463aAbdE3eE2c3 = USDC on Arbitrum\n        -- Normalize to lowercase for joining with token metadata\n        LOWER(funds_deposited_data_input_token) AS input_token_address,\n        \n        -- Output token: The token address to receive on the destination chain\n        -- Already decoded by ETL to proper address format\n        -- Example: 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48 = USDC on Ethereum\n        -- Normalize to lowercase for joining with token metadata\n        LOWER(funds_deposited_data_output_token) AS output_token_address,\n        \n        -- ============================================================\n        -- AMOUNT INFORMATION (how much was deposited)\n        -- ============================================================\n        \n        -- Input amount: How much was deposited on the origin chain\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\n        -- Store as RAW amount first (before rescaling by decimals)\n        funds_deposited_data_input_amount::NUMERIC AS input_amount_raw,\n        \n        -- Output amount: Expected amount to receive on destination chain\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\n        -- Store as RAW amount first (before rescaling by decimals)\n        funds_deposited_data_output_amount::NUMERIC AS output_amount_raw,\n        \n        -- ============================================================\n        -- TIMING INFORMATION (deadlines and quotes)\n        -- ============================================================\n        -- NOTE: These fields are NOT required for capital flow analysis and are commented out in database schema\n        \n        -- Quote timestamp: When the exchange rate quote was generated\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\n        -- Used to determine which exchange rate was used for the bridge\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\n        -- (funds_deposited_data_quote_timestamp::NUMERIC)::BIGINT AS quote_timestamp,\n        \n        -- Fill deadline: Latest timestamp by which the deposit must be filled\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\n        -- If not filled by this time, the deposit can be refunded\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\n        -- (funds_deposited_data_fill_deadline::NUMERIC)::BIGINT AS fill_deadline,\n        \n        -- Exclusivity deadline: Latest timestamp for exclusive relayer rights\n        -- Already converted by ETL from hex to numeric (stored as text in raw table)\n        -- Before this deadline, only the exclusive_relayer can fill this deposit\n        -- Cast via NUMERIC first to handle decimal strings like \"1733234567.0\" from ETL\n        -- (funds_deposited_data_exclusivity_deadline::NUMERIC)::BIGINT AS exclusivity_deadline,\n        \n        -- ============================================================\n        -- USER & RELAYER INFORMATION\n        -- ============================================================\n        \n        -- Recipient: Who receives the funds on the destination chain\n        -- Already decoded by ETL to proper address format\n        -- Usually the same as depositor, but can be different (gift/transfer)\n        funds_deposited_data_recipient AS recipient_address\n        \n        -- Exclusive relayer: Address with exclusive fill rights (if any)\n        -- Already decoded by ETL to proper address format\n        -- Used for priority/guaranteed fills (NULL if no exclusive relayer)\n        -- NOTE: Field is NOT required for capital flow analysis and is commented out in database schema\n        -- funds_deposited_data_exclusive_relayer AS exclusive_relayer_address\n        \n    FROM raw_deposits\n)\n\n\n-- ============================================================\n-- FINAL SELECT: Join with token metadata and rescale amounts\n-- ============================================================\nSELECT\n    -- Event identity\n    c.deposit_timestamp,\n    c.transaction_hash,\n    c.blockchain,\n    c.source_file,\n    \n    -- Indexed fields\n    c.destination_chain_id,\n    c.deposit_id,\n    c.depositor_address,\n    \n    -- \u2728 NEW: Token information WITH NAMES\n    -- Input token (what was deposited on origin chain - Arbitrum)\n    c.input_token_address,\n    input_tok.token_symbol AS input_token_symbol,        -- e.g., 'USDC', 'WETH'\n    \n    -- Output token (what will be received on destination chain)\n    c.output_token_address,\n    output_tok.token_symbol AS output_token_symbol,      -- e.g., 'USDC', 'WETH'\n    \n    -- \u2728 NEW: Rescaled amounts (human-readable)\n    -- These use the rescale_amount macro which divides raw amount by 10^decimals\n    -- Example: 5000000 raw USDC (6 decimals) \u2192 5.0 USDC\n    \n    c.input_amount_raw / POWER(10, COALESCE(input_tok.decimals, 18))\n AS input_amount,\n    \n    c.output_amount_raw / POWER(10, COALESCE(output_tok.decimals, 18))\n AS output_amount,\n    \n    -- \u2728 NEW: Raw amounts (preserved for auditing)\n    -- These are the original blockchain values before rescaling\n    -- Example: 5.0 USDC is stored as 5000000 on blockchain\n    c.input_amount_raw,\n    c.output_amount_raw,\n    \n    -- Timing (commented out - available in schema but not included in output)\n    -- quote_timestamp,\n    -- fill_deadline,\n    -- exclusivity_deadline,\n    \n    -- User info\n    c.recipient_address\n    -- exclusive_relayer_address  -- Commented out - available in schema but not included in output\n    \nFROM cleaned_deposits c\n\n-- Join with token metadata to get decimals and symbols for INPUT token\nLEFT JOIN token_decimals AS input_tok\n    ON c.input_token_address = input_tok.token_address\n\n-- Join with token metadata to get decimals and symbols for OUTPUT token\nLEFT JOIN token_decimals AS output_tok\n    ON c.output_token_address = output_tok.token_address\n\n-- Data quality: Only include rows with essential fields populated\nWHERE c.deposit_id IS NOT NULL\n    AND c.depositor_address IS NOT NULL\n    AND c.input_token_address IS NOT NULL\n    AND c.output_token_address IS NOT NULL\n    AND c.input_amount_raw IS NOT NULL\n    AND c.output_amount_raw IS NOT NULL", "relation_name": "\"across_analytics\".\"dbt_staging\".\"stg_arbitrum__deposits\"", "batch_results": null}], "elapsed_time": 1.2051141262054443, "args": {"which": "run", "require_yaml_configuration_for_mf_time_spines": false, "profiles_dir": "C:\\Users\\Longin\\.dbt", "require_all_warnings_handled_by_warn_error": false, "quiet": false, "indirect_selection": "eager", "require_resource_names_without_spaces": true, "validate_macro_args": false, "log_level": "info", "populate_cache": true, "state_modified_compare_more_unrendered_values": false, "write_json": true, "skip_nodes_if_on_run_start_fails": false, "use_colors": true, "empty": false, "log_path": "C:\\Users\\Longin\\Desktop\\Projects\\across_analytics\\logs", "use_colors_file": true, "favor_state": false, "require_batched_execution_for_custom_microbatch_strategy": false, "vars": {}, "cache_selected_only": false, "source_freshness_run_project_hooks": true, "warn_error_options": {"error": [], "warn": [], "silence": []}, "exclude": [], "log_file_max_bytes": 10485760, "invocation_command": "dbt run --select stg_arbitrum__deposits", "strict_mode": false, "upload_to_artifacts_ingest_api": false, "select": ["stg_arbitrum__deposits"], "static_parser": true, "log_format": "default", "require_generic_test_arguments_property": true, "version_check": true, "use_fast_test_edges": false, "project_dir": "C:\\Users\\Longin\\Desktop\\Projects\\across_analytics", "log_level_file": "debug", "log_format_file": "debug", "partial_parse": true, "partial_parse_file_diff": true, "printer_width": 80, "show_all_deprecations": false, "state_modified_compare_vars": false, "defer": false, "require_nested_cumulative_type_params": false, "send_anonymous_usage_stats": true, "macro_debugging": false, "require_explicit_package_overrides_for_builtin_materializations": true, "print": true, "introspect": true, "show_resource_report": false}}